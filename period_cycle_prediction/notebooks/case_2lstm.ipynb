{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import explained_variance_score\n",
    "from sklearn.metrics import max_error\n",
    "from utils.utils import generate_synthetic_data, generate_final_features, split_dataset\n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "regular_cycle_data = pd.read_csv('dataset/regular_cycle_data.csv')\n",
    "features_regular_cycle_data, labels_regular_cycle_data = generate_final_features(regular_cycle_data)\n",
    "input_train_regular_cycle, input_test_regular_cycle, output_train_regular_cycle, output_test_regular_cycle = split_dataset(features_regular_cycle_data, labels_regular_cycle_data, reshape=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-25 18:58:16.642015: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-05-25 18:58:16.643923: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-05-25 18:58:16.645680: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-05-25 18:58:16.891572: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-05-25 18:58:16.893366: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-05-25 18:58:16.894782: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-05-25 18:58:17.085617: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-05-25 18:58:17.087589: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-05-25 18:58:17.089228: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    }
   ],
   "source": [
    "n_features = input_train_regular_cycle.shape[2]\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=128, return_sequences=True, input_shape=(input_train_regular_cycle.shape[1], input_train_regular_cycle.shape[2])))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(units=64, return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(units=32))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(units=n_features, activation='relu'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt=tf.keras.optimizers.Adam()\n",
    "model.compile(loss='mean_squared_error', optimizer=opt)\n",
    "# add early stopping\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping( monitor='val_loss', patience=10, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-25 18:58:17.863962: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-05-25 18:58:17.866134: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-05-25 18:58:17.867555: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-05-25 18:58:18.041673: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-05-25 18:58:18.043105: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-05-25 18:58:18.044449: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-05-25 18:58:18.272783: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-05-25 18:58:18.275192: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-05-25 18:58:18.276484: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-05-25 18:58:19.331511: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-05-25 18:58:19.333238: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-05-25 18:58:19.334576: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-05-25 18:58:19.508869: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-05-25 18:58:19.510298: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-05-25 18:58:19.511600: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-05-25 18:58:19.688437: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-05-25 18:58:19.690318: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-05-25 18:58:19.691812: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - ETA: 0s - loss: 510.2717"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-25 18:58:22.269466: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-05-25 18:58:22.282675: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-05-25 18:58:22.288047: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-05-25 18:58:22.524562: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-05-25 18:58:22.526348: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-05-25 18:58:22.527685: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-05-25 18:58:22.697109: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-05-25 18:58:22.698412: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-05-25 18:58:22.699842: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 5s 5s/step - loss: 510.2717 - val_loss: 493.2679\n",
      "Epoch 2/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 506.5592 - val_loss: 489.3393\n",
      "Epoch 3/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 502.3734 - val_loss: 485.2707\n",
      "Epoch 4/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 497.9018 - val_loss: 480.9848\n",
      "Epoch 5/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 495.7454 - val_loss: 476.4270\n",
      "Epoch 6/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 491.2298 - val_loss: 471.5016\n",
      "Epoch 7/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 485.3932 - val_loss: 466.1425\n",
      "Epoch 8/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 480.6462 - val_loss: 460.3221\n",
      "Epoch 9/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 473.0695 - val_loss: 454.0372\n",
      "Epoch 10/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 467.2459 - val_loss: 447.3270\n",
      "Epoch 11/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 460.1122 - val_loss: 440.2466\n",
      "Epoch 12/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 451.7500 - val_loss: 432.8793\n",
      "Epoch 13/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 444.9655 - val_loss: 425.3297\n",
      "Epoch 14/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 438.2269 - val_loss: 417.6938\n",
      "Epoch 15/2000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 428.5270 - val_loss: 410.0568\n",
      "Epoch 16/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 422.2672 - val_loss: 402.4992\n",
      "Epoch 17/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 415.6531 - val_loss: 395.0773\n",
      "Epoch 18/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 414.2957 - val_loss: 387.8669\n",
      "Epoch 19/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 402.5910 - val_loss: 380.9018\n",
      "Epoch 20/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 395.5562 - val_loss: 374.2132\n",
      "Epoch 21/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 390.6723 - val_loss: 367.8327\n",
      "Epoch 22/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 386.7599 - val_loss: 361.7755\n",
      "Epoch 23/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 373.8374 - val_loss: 356.0430\n",
      "Epoch 24/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 375.8087 - val_loss: 350.6477\n",
      "Epoch 25/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 360.8447 - val_loss: 345.5706\n",
      "Epoch 26/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 355.6399 - val_loss: 340.8047\n",
      "Epoch 27/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 351.6460 - val_loss: 336.3369\n",
      "Epoch 28/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 349.6856 - val_loss: 332.1498\n",
      "Epoch 29/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 348.0179 - val_loss: 328.0535\n",
      "Epoch 30/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 337.5740 - val_loss: 324.2152\n",
      "Epoch 31/2000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 338.6364 - val_loss: 320.6202\n",
      "Epoch 32/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 332.7522 - val_loss: 317.2521\n",
      "Epoch 33/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 319.7701 - val_loss: 314.0909\n",
      "Epoch 34/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 319.0988 - val_loss: 311.1245\n",
      "Epoch 35/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 325.8918 - val_loss: 308.3419\n",
      "Epoch 36/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 326.8072 - val_loss: 305.7239\n",
      "Epoch 37/2000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 321.6730 - val_loss: 303.2524\n",
      "Epoch 38/2000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 318.0439 - val_loss: 300.9073\n",
      "Epoch 39/2000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 316.6775 - val_loss: 298.6875\n",
      "Epoch 40/2000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 299.3123 - val_loss: 296.5583\n",
      "Epoch 41/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 305.1459 - val_loss: 294.5135\n",
      "Epoch 42/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 298.6000 - val_loss: 292.5381\n",
      "Epoch 43/2000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 309.6647 - val_loss: 290.6312\n",
      "Epoch 44/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 301.5540 - val_loss: 288.7752\n",
      "Epoch 45/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 293.4090 - val_loss: 286.9628\n",
      "Epoch 46/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 294.4563 - val_loss: 285.1896\n",
      "Epoch 47/2000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 298.4113 - val_loss: 283.4514\n",
      "Epoch 48/2000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 293.2920 - val_loss: 281.7442\n",
      "Epoch 49/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 293.8964 - val_loss: 280.0720\n",
      "Epoch 50/2000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 280.8094 - val_loss: 278.4286\n",
      "Epoch 51/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 294.5838 - val_loss: 276.8189\n",
      "Epoch 52/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 277.5049 - val_loss: 275.2393\n",
      "Epoch 53/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 287.1165 - val_loss: 273.6922\n",
      "Epoch 54/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 286.4133 - val_loss: 272.1741\n",
      "Epoch 55/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 280.0015 - val_loss: 270.6886\n",
      "Epoch 56/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 282.6165 - val_loss: 269.2381\n",
      "Epoch 57/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 274.3363 - val_loss: 267.8180\n",
      "Epoch 58/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 279.7911 - val_loss: 266.4323\n",
      "Epoch 59/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 274.1063 - val_loss: 265.0798\n",
      "Epoch 60/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 277.1337 - val_loss: 263.7585\n",
      "Epoch 61/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 275.2177 - val_loss: 262.4669\n",
      "Epoch 62/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 275.0434 - val_loss: 261.2061\n",
      "Epoch 63/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 265.6827 - val_loss: 259.9728\n",
      "Epoch 64/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 274.5633 - val_loss: 258.7689\n",
      "Epoch 65/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 274.9959 - val_loss: 257.5916\n",
      "Epoch 66/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 268.5560 - val_loss: 256.4377\n",
      "Epoch 67/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 255.9648 - val_loss: 255.3007\n",
      "Epoch 68/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 262.6359 - val_loss: 254.1836\n",
      "Epoch 69/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 260.7943 - val_loss: 253.0826\n",
      "Epoch 70/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 261.1652 - val_loss: 251.9966\n",
      "Epoch 71/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 263.0913 - val_loss: 250.9271\n",
      "Epoch 72/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 262.8139 - val_loss: 249.8723\n",
      "Epoch 73/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 261.6885 - val_loss: 248.8310\n",
      "Epoch 74/2000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 246.9167 - val_loss: 247.8012\n",
      "Epoch 75/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 246.1489 - val_loss: 246.7825\n",
      "Epoch 76/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 259.6783 - val_loss: 245.7764\n",
      "Epoch 77/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 257.5908 - val_loss: 244.7815\n",
      "Epoch 78/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 243.7145 - val_loss: 243.7959\n",
      "Epoch 79/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 244.0932 - val_loss: 242.8176\n",
      "Epoch 80/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 252.3152 - val_loss: 241.8495\n",
      "Epoch 81/2000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 250.1722 - val_loss: 240.8899\n",
      "Epoch 82/2000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 252.3442 - val_loss: 239.9399\n",
      "Epoch 83/2000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 242.9951 - val_loss: 238.9984\n",
      "Epoch 84/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 256.5508 - val_loss: 238.0664\n",
      "Epoch 85/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 238.0184 - val_loss: 237.1422\n",
      "Epoch 86/2000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 243.7785 - val_loss: 236.2255\n",
      "Epoch 87/2000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 236.1020 - val_loss: 235.3150\n",
      "Epoch 88/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 237.7759 - val_loss: 234.4104\n",
      "Epoch 89/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 234.2626 - val_loss: 233.5123\n",
      "Epoch 90/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 240.4895 - val_loss: 232.6215\n",
      "Epoch 91/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 248.2054 - val_loss: 231.7382\n",
      "Epoch 92/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 243.0614 - val_loss: 230.8619\n",
      "Epoch 93/2000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 234.3918 - val_loss: 229.9916\n",
      "Epoch 94/2000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 236.8471 - val_loss: 229.1262\n",
      "Epoch 95/2000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 243.0962 - val_loss: 228.2678\n",
      "Epoch 96/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 236.5511 - val_loss: 227.4147\n",
      "Epoch 97/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 233.2539 - val_loss: 226.5665\n",
      "Epoch 98/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 221.5367 - val_loss: 225.7232\n",
      "Epoch 99/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 241.2330 - val_loss: 224.8874\n",
      "Epoch 100/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 233.6827 - val_loss: 224.0565\n",
      "Epoch 101/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 224.7238 - val_loss: 223.2311\n",
      "Epoch 102/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 225.4071 - val_loss: 222.4090\n",
      "Epoch 103/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 238.7903 - val_loss: 221.5928\n",
      "Epoch 104/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 228.1764 - val_loss: 220.7817\n",
      "Epoch 105/2000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 233.4321 - val_loss: 219.9763\n",
      "Epoch 106/2000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 225.4625 - val_loss: 219.1752\n",
      "Epoch 107/2000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 232.0850 - val_loss: 218.3796\n",
      "Epoch 108/2000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 232.0604 - val_loss: 217.5890\n",
      "Epoch 109/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 228.8905 - val_loss: 216.8033\n",
      "Epoch 110/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 232.5947 - val_loss: 216.0226\n",
      "Epoch 111/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 221.9949 - val_loss: 215.2460\n",
      "Epoch 112/2000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 225.4198 - val_loss: 214.4747\n",
      "Epoch 113/2000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 222.7668 - val_loss: 213.7080\n",
      "Epoch 114/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 219.4722 - val_loss: 212.9449\n",
      "Epoch 115/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 228.7504 - val_loss: 212.1870\n",
      "Epoch 116/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 219.0372 - val_loss: 211.4323\n",
      "Epoch 117/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 224.5933 - val_loss: 210.6825\n",
      "Epoch 118/2000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 213.2387 - val_loss: 209.9363\n",
      "Epoch 119/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 213.9469 - val_loss: 209.1930\n",
      "Epoch 120/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 218.2707 - val_loss: 208.4548\n",
      "Epoch 121/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 224.5549 - val_loss: 207.7203\n",
      "Epoch 122/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 232.9966 - val_loss: 206.9906\n",
      "Epoch 123/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 217.1778 - val_loss: 206.2637\n",
      "Epoch 124/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 211.5062 - val_loss: 205.5407\n",
      "Epoch 125/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 210.9678 - val_loss: 204.8202\n",
      "Epoch 126/2000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 217.1454 - val_loss: 204.1028\n",
      "Epoch 127/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 208.3696 - val_loss: 203.3892\n",
      "Epoch 128/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 214.2801 - val_loss: 202.6785\n",
      "Epoch 129/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 213.8024 - val_loss: 201.9715\n",
      "Epoch 130/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 207.7017 - val_loss: 201.2675\n",
      "Epoch 131/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 202.2891 - val_loss: 200.5664\n",
      "Epoch 132/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 213.4665 - val_loss: 199.8689\n",
      "Epoch 133/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 219.3295 - val_loss: 199.1750\n",
      "Epoch 134/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 199.0004 - val_loss: 198.4822\n",
      "Epoch 135/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 208.9835 - val_loss: 197.7914\n",
      "Epoch 136/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 207.3475 - val_loss: 197.1041\n",
      "Epoch 137/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 195.6036 - val_loss: 196.4190\n",
      "Epoch 138/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 195.6773 - val_loss: 195.7357\n",
      "Epoch 139/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 203.0531 - val_loss: 195.0557\n",
      "Epoch 140/2000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 205.4039 - val_loss: 194.3784\n",
      "Epoch 141/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 198.3138 - val_loss: 193.7035\n",
      "Epoch 142/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 205.2643 - val_loss: 193.0325\n",
      "Epoch 143/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 200.4028 - val_loss: 192.3652\n",
      "Epoch 144/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 192.6192 - val_loss: 191.6998\n",
      "Epoch 145/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 202.7878 - val_loss: 191.0372\n",
      "Epoch 146/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 204.6358 - val_loss: 190.3775\n",
      "Epoch 147/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 213.7688 - val_loss: 189.7214\n",
      "Epoch 148/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 200.0535 - val_loss: 189.0675\n",
      "Epoch 149/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 202.5159 - val_loss: 188.4171\n",
      "Epoch 150/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 201.9048 - val_loss: 187.7690\n",
      "Epoch 151/2000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 202.0036 - val_loss: 187.1237\n",
      "Epoch 152/2000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 205.7800 - val_loss: 186.4812\n",
      "Epoch 153/2000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 205.8457 - val_loss: 185.8416\n",
      "Epoch 154/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 192.5483 - val_loss: 185.2030\n",
      "Epoch 155/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 188.2410 - val_loss: 184.5667\n",
      "Epoch 156/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 189.3870 - val_loss: 183.9339\n",
      "Epoch 157/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 191.4985 - val_loss: 183.3029\n",
      "Epoch 158/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 194.3078 - val_loss: 182.6745\n",
      "Epoch 159/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 185.0287 - val_loss: 182.0485\n",
      "Epoch 160/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 185.9182 - val_loss: 181.4252\n",
      "Epoch 161/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 187.0595 - val_loss: 180.8042\n",
      "Epoch 162/2000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 185.5449 - val_loss: 180.1851\n",
      "Epoch 163/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 187.5569 - val_loss: 179.5674\n",
      "Epoch 164/2000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 181.5802 - val_loss: 178.9517\n",
      "Epoch 165/2000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 188.3518 - val_loss: 178.3386\n",
      "Epoch 166/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 184.1202 - val_loss: 177.7284\n",
      "Epoch 167/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 190.7482 - val_loss: 177.1207\n",
      "Epoch 168/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 176.0814 - val_loss: 176.5152\n",
      "Epoch 169/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 190.4910 - val_loss: 175.9125\n",
      "Epoch 170/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 178.4552 - val_loss: 175.3112\n",
      "Epoch 171/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 189.2196 - val_loss: 174.7129\n",
      "Epoch 172/2000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 189.6042 - val_loss: 174.1179\n",
      "Epoch 173/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 182.7811 - val_loss: 173.5247\n",
      "Epoch 174/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 179.5089 - val_loss: 172.9338\n",
      "Epoch 175/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 180.8697 - val_loss: 172.3448\n",
      "Epoch 176/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 190.4679 - val_loss: 171.7575\n",
      "Epoch 177/2000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 178.9972 - val_loss: 171.1710\n",
      "Epoch 178/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 178.2515 - val_loss: 170.5864\n",
      "Epoch 179/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 170.0786 - val_loss: 170.0033\n",
      "Epoch 180/2000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 178.6979 - val_loss: 169.4218\n",
      "Epoch 181/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 179.0611 - val_loss: 168.8426\n",
      "Epoch 182/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 183.4200 - val_loss: 168.2657\n",
      "Epoch 183/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 182.0354 - val_loss: 167.6910\n",
      "Epoch 184/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 174.9478 - val_loss: 167.1177\n",
      "Epoch 185/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 172.4114 - val_loss: 166.5467\n",
      "Epoch 186/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 158.6055 - val_loss: 165.9768\n",
      "Epoch 187/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 163.7278 - val_loss: 165.4088\n",
      "Epoch 188/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 176.4338 - val_loss: 164.8432\n",
      "Epoch 189/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 171.1492 - val_loss: 164.2793\n",
      "Epoch 190/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 181.8013 - val_loss: 163.7175\n",
      "Epoch 191/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 164.6068 - val_loss: 163.1577\n",
      "Epoch 192/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 169.3442 - val_loss: 162.5993\n",
      "Epoch 193/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 177.2815 - val_loss: 162.0428\n",
      "Epoch 194/2000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 176.9220 - val_loss: 161.4891\n",
      "Epoch 195/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 166.2469 - val_loss: 160.9381\n",
      "Epoch 196/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 179.8597 - val_loss: 160.3886\n",
      "Epoch 197/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 157.4600 - val_loss: 159.8401\n",
      "Epoch 198/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 156.5966 - val_loss: 159.2932\n",
      "Epoch 199/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 169.2496 - val_loss: 158.7486\n",
      "Epoch 200/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 158.5943 - val_loss: 158.2059\n",
      "Epoch 201/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 171.5195 - val_loss: 157.6646\n",
      "Epoch 202/2000\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 178.6670 - val_loss: 157.1253\n",
      "Epoch 203/2000\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 165.0863 - val_loss: 156.5880\n",
      "Epoch 204/2000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 162.5609 - val_loss: 156.0526\n",
      "Epoch 205/2000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 171.3915 - val_loss: 155.5188\n",
      "Epoch 206/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 171.8687 - val_loss: 154.9868\n",
      "Epoch 207/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 170.0036 - val_loss: 154.4564\n",
      "Epoch 208/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 161.8956 - val_loss: 153.9276\n",
      "Epoch 209/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 167.9529 - val_loss: 153.4005\n",
      "Epoch 210/2000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 166.6743 - val_loss: 152.8761\n",
      "Epoch 211/2000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 163.2567 - val_loss: 152.3535\n",
      "Epoch 212/2000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 155.2217 - val_loss: 151.8325\n",
      "Epoch 213/2000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 159.8041 - val_loss: 151.3123\n",
      "Epoch 214/2000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 165.9632 - val_loss: 150.7941\n",
      "Epoch 215/2000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 166.3166 - val_loss: 150.2774\n",
      "Epoch 216/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 177.0007 - val_loss: 149.7629\n",
      "Epoch 217/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 164.6426 - val_loss: 149.2497\n",
      "Epoch 218/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 149.6393 - val_loss: 148.7370\n",
      "Epoch 219/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 161.4550 - val_loss: 148.2258\n",
      "Epoch 220/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 155.1330 - val_loss: 147.7161\n",
      "Epoch 221/2000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 152.5335 - val_loss: 147.2076\n",
      "Epoch 222/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 154.0033 - val_loss: 146.7006\n",
      "Epoch 223/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 164.8563 - val_loss: 146.1957\n",
      "Epoch 224/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 151.4227 - val_loss: 145.6922\n",
      "Epoch 225/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 161.6488 - val_loss: 145.1908\n",
      "Epoch 226/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 152.6284 - val_loss: 144.6912\n",
      "Epoch 227/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 149.9699 - val_loss: 144.1930\n",
      "Epoch 228/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 145.6540 - val_loss: 143.6965\n",
      "Epoch 229/2000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 136.7854 - val_loss: 143.2011\n",
      "Epoch 230/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 147.3002 - val_loss: 142.7078\n",
      "Epoch 231/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 146.9355 - val_loss: 142.2159\n",
      "Epoch 232/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 150.9440 - val_loss: 141.7260\n",
      "Epoch 233/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 147.2518 - val_loss: 141.2373\n",
      "Epoch 234/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 147.7562 - val_loss: 140.7500\n",
      "Epoch 235/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 146.5506 - val_loss: 140.2642\n",
      "Epoch 236/2000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 153.1478 - val_loss: 139.7799\n",
      "Epoch 237/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 155.6759 - val_loss: 139.2975\n",
      "Epoch 238/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 139.8098 - val_loss: 138.8164\n",
      "Epoch 239/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 147.4593 - val_loss: 138.3367\n",
      "Epoch 240/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 139.0393 - val_loss: 137.8584\n",
      "Epoch 241/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 151.5857 - val_loss: 137.3819\n",
      "Epoch 242/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 144.6875 - val_loss: 136.9074\n",
      "Epoch 243/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 149.5258 - val_loss: 136.4341\n",
      "Epoch 244/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 145.3969 - val_loss: 135.9622\n",
      "Epoch 245/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 145.5832 - val_loss: 135.4914\n",
      "Epoch 246/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 136.9274 - val_loss: 135.0220\n",
      "Epoch 247/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 146.0806 - val_loss: 134.5537\n",
      "Epoch 248/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 138.0018 - val_loss: 134.0865\n",
      "Epoch 249/2000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 147.6604 - val_loss: 133.6207\n",
      "Epoch 250/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 129.8214 - val_loss: 133.1559\n",
      "Epoch 251/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 151.1137 - val_loss: 132.6930\n",
      "Epoch 252/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 143.9759 - val_loss: 132.2318\n",
      "Epoch 253/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 139.3593 - val_loss: 131.7726\n",
      "Epoch 254/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 125.6080 - val_loss: 131.3154\n",
      "Epoch 255/2000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 142.3283 - val_loss: 130.8598\n",
      "Epoch 256/2000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 135.7898 - val_loss: 130.4053\n",
      "Epoch 257/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 143.9204 - val_loss: 129.9520\n",
      "Epoch 258/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 153.2260 - val_loss: 129.5000\n",
      "Epoch 259/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 130.3416 - val_loss: 129.0493\n",
      "Epoch 260/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 121.1320 - val_loss: 128.6000\n",
      "Epoch 261/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 139.4804 - val_loss: 128.1521\n",
      "Epoch 262/2000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 140.7191 - val_loss: 127.7051\n",
      "Epoch 263/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 138.9517 - val_loss: 127.2592\n",
      "Epoch 264/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 137.4060 - val_loss: 126.8148\n",
      "Epoch 265/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 135.7906 - val_loss: 126.3719\n",
      "Epoch 266/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 134.2942 - val_loss: 125.9309\n",
      "Epoch 267/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 131.7040 - val_loss: 125.4914\n",
      "Epoch 268/2000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 144.4103 - val_loss: 125.0532\n",
      "Epoch 269/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 135.6311 - val_loss: 124.6163\n",
      "Epoch 270/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 131.2281 - val_loss: 124.1806\n",
      "Epoch 271/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 140.0037 - val_loss: 123.7458\n",
      "Epoch 272/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 119.3752 - val_loss: 123.3124\n",
      "Epoch 273/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 133.3298 - val_loss: 122.8801\n",
      "Epoch 274/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 122.3680 - val_loss: 122.4489\n",
      "Epoch 275/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 144.5006 - val_loss: 122.0186\n",
      "Epoch 276/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 129.2173 - val_loss: 121.5892\n",
      "Epoch 277/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 127.2365 - val_loss: 121.1612\n",
      "Epoch 278/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 128.8193 - val_loss: 120.7349\n",
      "Epoch 279/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 132.5407 - val_loss: 120.3098\n",
      "Epoch 280/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 122.3184 - val_loss: 119.8856\n",
      "Epoch 281/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 135.5611 - val_loss: 119.4628\n",
      "Epoch 282/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 115.3206 - val_loss: 119.0415\n",
      "Epoch 283/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 134.5123 - val_loss: 118.6212\n",
      "Epoch 284/2000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 119.5901 - val_loss: 118.2025\n",
      "Epoch 285/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 131.4767 - val_loss: 117.7843\n",
      "Epoch 286/2000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 119.8197 - val_loss: 117.3671\n",
      "Epoch 287/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 122.6533 - val_loss: 116.9512\n",
      "Epoch 288/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 120.3086 - val_loss: 116.5367\n",
      "Epoch 289/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 128.2371 - val_loss: 116.1225\n",
      "Epoch 290/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 135.6061 - val_loss: 115.7094\n",
      "Epoch 291/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 115.5443 - val_loss: 115.2974\n",
      "Epoch 292/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 131.1489 - val_loss: 114.8860\n",
      "Epoch 293/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 121.0299 - val_loss: 114.4758\n",
      "Epoch 294/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 114.6159 - val_loss: 114.0671\n",
      "Epoch 295/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 125.4564 - val_loss: 113.6601\n",
      "Epoch 296/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 127.5751 - val_loss: 113.2543\n",
      "Epoch 297/2000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 121.7274 - val_loss: 112.8496\n",
      "Epoch 298/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 120.9192 - val_loss: 112.4467\n",
      "Epoch 299/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 124.5416 - val_loss: 112.0450\n",
      "Epoch 300/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 122.3814 - val_loss: 111.6446\n",
      "Epoch 301/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 110.2450 - val_loss: 111.2451\n",
      "Epoch 302/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 123.0227 - val_loss: 110.8468\n",
      "Epoch 303/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 120.5496 - val_loss: 110.4490\n",
      "Epoch 304/2000\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 121.2200 - val_loss: 110.0518\n",
      "Epoch 305/2000\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 113.8019 - val_loss: 109.6562\n",
      "Epoch 306/2000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 110.7244 - val_loss: 109.2622\n",
      "Epoch 307/2000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 111.4273 - val_loss: 108.8696\n",
      "Epoch 308/2000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 117.9186 - val_loss: 108.4787\n",
      "Epoch 309/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 111.1324 - val_loss: 108.0891\n",
      "Epoch 310/2000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 112.8805 - val_loss: 107.7005\n",
      "Epoch 311/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 120.3081 - val_loss: 107.3131\n",
      "Epoch 312/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 110.7334 - val_loss: 106.9267\n",
      "Epoch 313/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 115.4928 - val_loss: 106.5415\n",
      "Epoch 314/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 118.9567 - val_loss: 106.1575\n",
      "Epoch 315/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 103.3638 - val_loss: 105.7751\n",
      "Epoch 316/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 118.2817 - val_loss: 105.3939\n",
      "Epoch 317/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 109.5891 - val_loss: 105.0140\n",
      "Epoch 318/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 107.8050 - val_loss: 104.6352\n",
      "Epoch 319/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 112.8374 - val_loss: 104.2584\n",
      "Epoch 320/2000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 103.5282 - val_loss: 103.8830\n",
      "Epoch 321/2000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 121.0308 - val_loss: 103.5082\n",
      "Epoch 322/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 110.3256 - val_loss: 103.1346\n",
      "Epoch 323/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 107.9013 - val_loss: 102.7621\n",
      "Epoch 324/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 109.5050 - val_loss: 102.3907\n",
      "Epoch 325/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 105.3918 - val_loss: 102.0206\n",
      "Epoch 326/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 106.9053 - val_loss: 101.6514\n",
      "Epoch 327/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 106.6966 - val_loss: 101.2832\n",
      "Epoch 328/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 97.2104 - val_loss: 100.9168\n",
      "Epoch 329/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 95.1392 - val_loss: 100.5520\n",
      "Epoch 330/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 106.4557 - val_loss: 100.1876\n",
      "Epoch 331/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 111.8129 - val_loss: 99.8241\n",
      "Epoch 332/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 113.4052 - val_loss: 99.4614\n",
      "Epoch 333/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 107.9234 - val_loss: 99.0995\n",
      "Epoch 334/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 102.7851 - val_loss: 98.7397\n",
      "Epoch 335/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 113.3160 - val_loss: 98.3806\n",
      "Epoch 336/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 105.5043 - val_loss: 98.0226\n",
      "Epoch 337/2000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 106.4284 - val_loss: 97.6655\n",
      "Epoch 338/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 114.5884 - val_loss: 97.3089\n",
      "Epoch 339/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 101.3983 - val_loss: 96.9534\n",
      "Epoch 340/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 98.9214 - val_loss: 96.5991\n",
      "Epoch 341/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 92.9230 - val_loss: 96.2465\n",
      "Epoch 342/2000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 103.9254 - val_loss: 95.8947\n",
      "Epoch 343/2000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 98.8512 - val_loss: 95.5441\n",
      "Epoch 344/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 104.1425 - val_loss: 95.1949\n",
      "Epoch 345/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 90.6292 - val_loss: 94.8473\n",
      "Epoch 346/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 100.3606 - val_loss: 94.5005\n",
      "Epoch 347/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 102.3266 - val_loss: 94.1545\n",
      "Epoch 348/2000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 96.4656 - val_loss: 93.8094\n",
      "Epoch 349/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 98.1279 - val_loss: 93.4656\n",
      "Epoch 350/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 96.4324 - val_loss: 93.1233\n",
      "Epoch 351/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 93.9298 - val_loss: 92.7825\n",
      "Epoch 352/2000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 100.4053 - val_loss: 92.4424\n",
      "Epoch 353/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 93.8647 - val_loss: 92.1036\n",
      "Epoch 354/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 108.4872 - val_loss: 91.7653\n",
      "Epoch 355/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 111.7432 - val_loss: 91.4277\n",
      "Epoch 356/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 102.2306 - val_loss: 91.0915\n",
      "Epoch 357/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 89.7068 - val_loss: 90.7566\n",
      "Epoch 358/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 87.3485 - val_loss: 90.4229\n",
      "Epoch 359/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 98.3108 - val_loss: 90.0902\n",
      "Epoch 360/2000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 103.9247 - val_loss: 89.7583\n",
      "Epoch 361/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 103.5998 - val_loss: 89.4269\n",
      "Epoch 362/2000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 98.2862 - val_loss: 89.0966\n",
      "Epoch 363/2000\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 100.4825 - val_loss: 88.7675\n",
      "Epoch 364/2000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 97.0667 - val_loss: 88.4388\n",
      "Epoch 365/2000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 95.1081 - val_loss: 88.1113\n",
      "Epoch 366/2000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 105.4807 - val_loss: 87.7843\n",
      "Epoch 367/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 90.7896 - val_loss: 87.4586\n",
      "Epoch 368/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 95.1915 - val_loss: 87.1339\n",
      "Epoch 369/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 94.7010 - val_loss: 86.8100\n",
      "Epoch 370/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 83.6092 - val_loss: 86.4875\n",
      "Epoch 371/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 85.7168 - val_loss: 86.1662\n",
      "Epoch 372/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 97.1235 - val_loss: 85.8453\n",
      "Epoch 373/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 93.2082 - val_loss: 85.5260\n",
      "Epoch 374/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 90.4787 - val_loss: 85.2077\n",
      "Epoch 375/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 99.4234 - val_loss: 84.8899\n",
      "Epoch 376/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 86.3890 - val_loss: 84.5734\n",
      "Epoch 377/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 97.5720 - val_loss: 84.2573\n",
      "Epoch 378/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 91.1413 - val_loss: 83.9422\n",
      "Epoch 379/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 106.1783 - val_loss: 83.6269\n",
      "Epoch 380/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 91.0268 - val_loss: 83.3126\n",
      "Epoch 381/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 93.9861 - val_loss: 82.9994\n",
      "Epoch 382/2000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 81.1127 - val_loss: 82.6873\n",
      "Epoch 383/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 88.2275 - val_loss: 82.3760\n",
      "Epoch 384/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 94.8057 - val_loss: 82.0651\n",
      "Epoch 385/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 94.9603 - val_loss: 81.7550\n",
      "Epoch 386/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 87.1567 - val_loss: 81.4462\n",
      "Epoch 387/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 80.3638 - val_loss: 81.1386\n",
      "Epoch 388/2000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 89.2661 - val_loss: 80.8322\n",
      "Epoch 389/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 82.6025 - val_loss: 80.5272\n",
      "Epoch 390/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 87.4926 - val_loss: 80.2229\n",
      "Epoch 391/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 88.7980 - val_loss: 79.9199\n",
      "Epoch 392/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 90.8947 - val_loss: 79.6173\n",
      "Epoch 393/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 96.6104 - val_loss: 79.3155\n",
      "Epoch 394/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 95.4749 - val_loss: 79.0140\n",
      "Epoch 395/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 84.1325 - val_loss: 78.7134\n",
      "Epoch 396/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 86.7088 - val_loss: 78.4136\n",
      "Epoch 397/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 80.8325 - val_loss: 78.1153\n",
      "Epoch 398/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 88.7138 - val_loss: 77.8180\n",
      "Epoch 399/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 87.8203 - val_loss: 77.5214\n",
      "Epoch 400/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 90.1445 - val_loss: 77.2252\n",
      "Epoch 401/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 82.6958 - val_loss: 76.9301\n",
      "Epoch 402/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 87.0405 - val_loss: 76.6357\n",
      "Epoch 403/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 74.9284 - val_loss: 76.3429\n",
      "Epoch 404/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 87.5608 - val_loss: 76.0513\n",
      "Epoch 405/2000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 89.8131 - val_loss: 75.7601\n",
      "Epoch 406/2000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 82.4171 - val_loss: 75.4697\n",
      "Epoch 407/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 92.1895 - val_loss: 75.1802\n",
      "Epoch 408/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 77.1654 - val_loss: 74.8921\n",
      "Epoch 409/2000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 76.7505 - val_loss: 74.6053\n",
      "Epoch 410/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 75.6269 - val_loss: 74.3195\n",
      "Epoch 411/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 71.4286 - val_loss: 74.0353\n",
      "Epoch 412/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 87.7382 - val_loss: 73.7513\n",
      "Epoch 413/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 72.1913 - val_loss: 73.4686\n",
      "Epoch 414/2000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 85.0151 - val_loss: 73.1868\n",
      "Epoch 415/2000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 80.8260 - val_loss: 72.9054\n",
      "Epoch 416/2000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 79.9163 - val_loss: 72.6249\n",
      "Epoch 417/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 78.8380 - val_loss: 72.3450\n",
      "Epoch 418/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 75.2313 - val_loss: 72.0664\n",
      "Epoch 419/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 74.0116 - val_loss: 71.7895\n",
      "Epoch 420/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 82.0373 - val_loss: 71.5136\n",
      "Epoch 421/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 87.1954 - val_loss: 71.2379\n",
      "Epoch 422/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 87.5013 - val_loss: 70.9628\n",
      "Epoch 423/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 82.1314 - val_loss: 70.6879\n",
      "Epoch 424/2000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 66.7476 - val_loss: 70.4150\n",
      "Epoch 425/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 78.2024 - val_loss: 70.1430\n",
      "Epoch 426/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 75.1625 - val_loss: 69.8720\n",
      "Epoch 427/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 70.9239 - val_loss: 69.6020\n",
      "Epoch 428/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 69.5637 - val_loss: 69.3338\n",
      "Epoch 429/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 80.5967 - val_loss: 69.0658\n",
      "Epoch 430/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 68.6966 - val_loss: 68.7990\n",
      "Epoch 431/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 73.5631 - val_loss: 68.5332\n",
      "Epoch 432/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 71.6618 - val_loss: 68.2681\n",
      "Epoch 433/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 69.0130 - val_loss: 68.0046\n",
      "Epoch 434/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 79.6050 - val_loss: 67.7413\n",
      "Epoch 435/2000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 75.2615 - val_loss: 67.4787\n",
      "Epoch 436/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 69.0072 - val_loss: 67.2169\n",
      "Epoch 437/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 74.4153 - val_loss: 66.9564\n",
      "Epoch 438/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 71.4423 - val_loss: 66.6971\n",
      "Epoch 439/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 80.5379 - val_loss: 66.4379\n",
      "Epoch 440/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 72.6583 - val_loss: 66.1792\n",
      "Epoch 441/2000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 76.2616 - val_loss: 65.9210\n",
      "Epoch 442/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 68.4917 - val_loss: 65.6636\n",
      "Epoch 443/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 78.4036 - val_loss: 65.4066\n",
      "Epoch 444/2000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 67.8904 - val_loss: 65.1506\n",
      "Epoch 445/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 69.9568 - val_loss: 64.8952\n",
      "Epoch 446/2000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 59.8799 - val_loss: 64.6417\n",
      "Epoch 447/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 82.2328 - val_loss: 64.3878\n",
      "Epoch 448/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 81.9666 - val_loss: 64.1340\n",
      "Epoch 449/2000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 63.4471 - val_loss: 63.8818\n",
      "Epoch 450/2000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 72.1604 - val_loss: 63.6298\n",
      "Epoch 451/2000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 78.9788 - val_loss: 63.3785\n",
      "Epoch 452/2000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 73.3238 - val_loss: 63.1278\n",
      "Epoch 453/2000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 70.9690 - val_loss: 62.8778\n",
      "Epoch 454/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 67.2038 - val_loss: 62.6285\n",
      "Epoch 455/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 73.4061 - val_loss: 62.3796\n",
      "Epoch 456/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 73.3603 - val_loss: 62.1317\n",
      "Epoch 457/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 69.1695 - val_loss: 61.8853\n",
      "Epoch 458/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 66.6761 - val_loss: 61.6400\n",
      "Epoch 459/2000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 63.7611 - val_loss: 61.3963\n",
      "Epoch 460/2000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 74.3426 - val_loss: 61.1528\n",
      "Epoch 461/2000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 70.4291 - val_loss: 60.9105\n",
      "Epoch 462/2000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 56.1575 - val_loss: 60.6701\n",
      "Epoch 463/2000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 73.1431 - val_loss: 60.4299\n",
      "Epoch 464/2000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 69.7904 - val_loss: 60.1900\n",
      "Epoch 465/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 66.4096 - val_loss: 59.9508\n",
      "Epoch 466/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 60.6688 - val_loss: 59.7128\n",
      "Epoch 467/2000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 71.8430 - val_loss: 59.4759\n",
      "Epoch 468/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 77.6482 - val_loss: 59.2387\n",
      "Epoch 469/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 64.5851 - val_loss: 59.0020\n",
      "Epoch 470/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 72.0811 - val_loss: 58.7655\n",
      "Epoch 471/2000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 64.1998 - val_loss: 58.5302\n",
      "Epoch 472/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 64.1295 - val_loss: 58.2958\n",
      "Epoch 473/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 59.6053 - val_loss: 58.0627\n",
      "Epoch 474/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 64.9768 - val_loss: 57.8308\n",
      "Epoch 475/2000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 58.9500 - val_loss: 57.6000\n",
      "Epoch 476/2000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 66.5135 - val_loss: 57.3698\n",
      "Epoch 477/2000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 56.9248 - val_loss: 57.1405\n",
      "Epoch 478/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 67.4610 - val_loss: 56.9119\n",
      "Epoch 479/2000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 70.9242 - val_loss: 56.6834\n",
      "Epoch 480/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 58.7547 - val_loss: 56.4559\n",
      "Epoch 481/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 62.8943 - val_loss: 56.2290\n",
      "Epoch 482/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 72.8664 - val_loss: 56.0015\n",
      "Epoch 483/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 67.5165 - val_loss: 55.7749\n",
      "Epoch 484/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 56.2186 - val_loss: 55.5495\n",
      "Epoch 485/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 64.5341 - val_loss: 55.3247\n",
      "Epoch 486/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 64.5708 - val_loss: 55.1012\n",
      "Epoch 487/2000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 61.2841 - val_loss: 54.8785\n",
      "Epoch 488/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 54.6851 - val_loss: 54.6573\n",
      "Epoch 489/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 59.8194 - val_loss: 54.4368\n",
      "Epoch 490/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 75.5778 - val_loss: 54.2159\n",
      "Epoch 491/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 62.3069 - val_loss: 53.9958\n",
      "Epoch 492/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 67.2359 - val_loss: 53.7764\n",
      "Epoch 493/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 53.3889 - val_loss: 53.5580\n",
      "Epoch 494/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 55.7969 - val_loss: 53.3407\n",
      "Epoch 495/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 49.1618 - val_loss: 53.1256\n",
      "Epoch 496/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 56.4708 - val_loss: 52.9113\n",
      "Epoch 497/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 60.4943 - val_loss: 52.6976\n",
      "Epoch 498/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 62.3989 - val_loss: 52.4843\n",
      "Epoch 499/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 55.6857 - val_loss: 52.2716\n",
      "Epoch 500/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 51.7726 - val_loss: 52.0598\n",
      "Epoch 501/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 55.4212 - val_loss: 51.8493\n",
      "Epoch 502/2000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 61.0296 - val_loss: 51.6392\n",
      "Epoch 503/2000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 76.2717 - val_loss: 51.4288\n",
      "Epoch 504/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 51.2787 - val_loss: 51.2196\n",
      "Epoch 505/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 53.1086 - val_loss: 51.0117\n",
      "Epoch 506/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 57.1999 - val_loss: 50.8042\n",
      "Epoch 507/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 61.3130 - val_loss: 50.5971\n",
      "Epoch 508/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 65.7054 - val_loss: 50.3900\n",
      "Epoch 509/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 55.0638 - val_loss: 50.1836\n",
      "Epoch 510/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 52.1505 - val_loss: 49.9787\n",
      "Epoch 511/2000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 57.5815 - val_loss: 49.7741\n",
      "Epoch 512/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 52.0056 - val_loss: 49.5704\n",
      "Epoch 513/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 53.5730 - val_loss: 49.3673\n",
      "Epoch 514/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 56.4168 - val_loss: 49.1649\n",
      "Epoch 515/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 50.6837 - val_loss: 48.9639\n",
      "Epoch 516/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 61.4333 - val_loss: 48.7639\n",
      "Epoch 517/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 56.5641 - val_loss: 48.5638\n",
      "Epoch 518/2000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 63.8422 - val_loss: 48.3635\n",
      "Epoch 519/2000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 56.2122 - val_loss: 48.1637\n",
      "Epoch 520/2000\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 42.2199 - val_loss: 47.9660\n",
      "Epoch 521/2000\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 46.7446 - val_loss: 47.7697\n",
      "Epoch 522/2000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 50.0385 - val_loss: 47.5745\n",
      "Epoch 523/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 63.5523 - val_loss: 47.3782\n",
      "Epoch 524/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 52.1737 - val_loss: 47.1823\n",
      "Epoch 525/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 55.8944 - val_loss: 46.9864\n",
      "Epoch 526/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 53.6736 - val_loss: 46.7912\n",
      "Epoch 527/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 55.6539 - val_loss: 46.5963\n",
      "Epoch 528/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 49.2151 - val_loss: 46.4023\n",
      "Epoch 529/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 53.3853 - val_loss: 46.2090\n",
      "Epoch 530/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 45.4785 - val_loss: 46.0171\n",
      "Epoch 531/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 57.0803 - val_loss: 45.8268\n",
      "Epoch 532/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 53.6293 - val_loss: 45.6375\n",
      "Epoch 533/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 52.1990 - val_loss: 45.4483\n",
      "Epoch 534/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 43.5418 - val_loss: 45.2610\n",
      "Epoch 535/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 46.5062 - val_loss: 45.0747\n",
      "Epoch 536/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 59.5851 - val_loss: 44.8880\n",
      "Epoch 537/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 50.4183 - val_loss: 44.7023\n",
      "Epoch 538/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 53.3459 - val_loss: 44.5171\n",
      "Epoch 539/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 47.7843 - val_loss: 44.3330\n",
      "Epoch 540/2000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 44.6721 - val_loss: 44.1502\n",
      "Epoch 541/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 52.4707 - val_loss: 43.9675\n",
      "Epoch 542/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 42.3385 - val_loss: 43.7861\n",
      "Epoch 543/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 49.5026 - val_loss: 43.6049\n",
      "Epoch 544/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 45.7116 - val_loss: 43.4250\n",
      "Epoch 545/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 39.2570 - val_loss: 43.2472\n",
      "Epoch 546/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 53.1817 - val_loss: 43.0687\n",
      "Epoch 547/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 48.7372 - val_loss: 42.8904\n",
      "Epoch 548/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 46.2406 - val_loss: 42.7128\n",
      "Epoch 549/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 53.6575 - val_loss: 42.5351\n",
      "Epoch 550/2000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 52.6291 - val_loss: 42.3577\n",
      "Epoch 551/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 45.5577 - val_loss: 42.1813\n",
      "Epoch 552/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 50.0193 - val_loss: 42.0049\n",
      "Epoch 553/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 42.9900 - val_loss: 41.8298\n",
      "Epoch 554/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 58.5310 - val_loss: 41.6547\n",
      "Epoch 555/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 41.5581 - val_loss: 41.4806\n",
      "Epoch 556/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 45.2767 - val_loss: 41.3077\n",
      "Epoch 557/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 46.1273 - val_loss: 41.1354\n",
      "Epoch 558/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 53.2073 - val_loss: 40.9629\n",
      "Epoch 559/2000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 49.1052 - val_loss: 40.7908\n",
      "Epoch 560/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 49.8470 - val_loss: 40.6191\n",
      "Epoch 561/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 45.6617 - val_loss: 40.4484\n",
      "Epoch 562/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 43.0392 - val_loss: 40.2787\n",
      "Epoch 563/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 50.8531 - val_loss: 40.1086\n",
      "Epoch 564/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 43.7753 - val_loss: 39.9393\n",
      "Epoch 565/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 50.8327 - val_loss: 39.7701\n",
      "Epoch 566/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 42.2839 - val_loss: 39.6021\n",
      "Epoch 567/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 54.1604 - val_loss: 39.4345\n",
      "Epoch 568/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 49.3456 - val_loss: 39.2673\n",
      "Epoch 569/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 48.5576 - val_loss: 39.1004\n",
      "Epoch 570/2000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 47.9689 - val_loss: 38.9341\n",
      "Epoch 571/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 40.2290 - val_loss: 38.7691\n",
      "Epoch 572/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 39.5805 - val_loss: 38.6051\n",
      "Epoch 573/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 50.2690 - val_loss: 38.4412\n",
      "Epoch 574/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 47.7766 - val_loss: 38.2775\n",
      "Epoch 575/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 56.5339 - val_loss: 38.1135\n",
      "Epoch 576/2000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 48.7290 - val_loss: 37.9500\n",
      "Epoch 577/2000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 41.2282 - val_loss: 37.7876\n",
      "Epoch 578/2000\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 30.6269 - val_loss: 37.6276\n",
      "Epoch 579/2000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 49.0962 - val_loss: 37.4674\n",
      "Epoch 580/2000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 44.0094 - val_loss: 37.3079\n",
      "Epoch 581/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 40.6482 - val_loss: 37.1495\n",
      "Epoch 582/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 46.9760 - val_loss: 36.9912\n",
      "Epoch 583/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 36.4334 - val_loss: 36.8340\n",
      "Epoch 584/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 46.7861 - val_loss: 36.6767\n",
      "Epoch 585/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 50.8859 - val_loss: 36.5186\n",
      "Epoch 586/2000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 49.9226 - val_loss: 36.3600\n",
      "Epoch 587/2000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 41.7504 - val_loss: 36.2024\n",
      "Epoch 588/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 36.8670 - val_loss: 36.0461\n",
      "Epoch 589/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 51.4186 - val_loss: 35.8889\n",
      "Epoch 590/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 48.2187 - val_loss: 35.7316\n",
      "Epoch 591/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 39.1693 - val_loss: 35.5755\n",
      "Epoch 592/2000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 40.0710 - val_loss: 35.4206\n",
      "Epoch 593/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 45.5512 - val_loss: 35.2660\n",
      "Epoch 594/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 44.8500 - val_loss: 35.1121\n",
      "Epoch 595/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 43.8926 - val_loss: 34.9586\n",
      "Epoch 596/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 45.7713 - val_loss: 34.8048\n",
      "Epoch 597/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 50.8558 - val_loss: 34.6510\n",
      "Epoch 598/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 39.0421 - val_loss: 34.4981\n",
      "Epoch 599/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 40.7231 - val_loss: 34.3462\n",
      "Epoch 600/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 54.0670 - val_loss: 34.1938\n",
      "Epoch 601/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 37.3456 - val_loss: 34.0425\n",
      "Epoch 602/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 54.4778 - val_loss: 33.8905\n",
      "Epoch 603/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 46.5746 - val_loss: 33.7388\n",
      "Epoch 604/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 44.7087 - val_loss: 33.5876\n",
      "Epoch 605/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 43.8618 - val_loss: 33.4373\n",
      "Epoch 606/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 39.0043 - val_loss: 33.2881\n",
      "Epoch 607/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 41.7271 - val_loss: 33.1402\n",
      "Epoch 608/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 37.7496 - val_loss: 32.9929\n",
      "Epoch 609/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 36.9144 - val_loss: 32.8470\n",
      "Epoch 610/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 42.0432 - val_loss: 32.7020\n",
      "Epoch 611/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 33.7367 - val_loss: 32.5589\n",
      "Epoch 612/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 35.0509 - val_loss: 32.4169\n",
      "Epoch 613/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 34.0428 - val_loss: 32.2761\n",
      "Epoch 614/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 31.8671 - val_loss: 32.1365\n",
      "Epoch 615/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 38.8378 - val_loss: 31.9971\n",
      "Epoch 616/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 48.3743 - val_loss: 31.8570\n",
      "Epoch 617/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 39.7428 - val_loss: 31.7177\n",
      "Epoch 618/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 30.3646 - val_loss: 31.5796\n",
      "Epoch 619/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 35.5543 - val_loss: 31.4426\n",
      "Epoch 620/2000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 37.3849 - val_loss: 31.3060\n",
      "Epoch 621/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 43.9124 - val_loss: 31.1698\n",
      "Epoch 622/2000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 33.5390 - val_loss: 31.0347\n",
      "Epoch 623/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 48.5803 - val_loss: 30.8990\n",
      "Epoch 624/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 34.3777 - val_loss: 30.7647\n",
      "Epoch 625/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 42.7920 - val_loss: 30.6296\n",
      "Epoch 626/2000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 42.0652 - val_loss: 30.4942\n",
      "Epoch 627/2000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 40.4786 - val_loss: 30.3591\n",
      "Epoch 628/2000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 35.4480 - val_loss: 30.2244\n",
      "Epoch 629/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 39.5610 - val_loss: 30.0902\n",
      "Epoch 630/2000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 27.2856 - val_loss: 29.9583\n",
      "Epoch 631/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 25.1614 - val_loss: 29.8291\n",
      "Epoch 632/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 40.0990 - val_loss: 29.6992\n",
      "Epoch 633/2000\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 31.1992 - val_loss: 29.5706\n",
      "Epoch 634/2000\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 36.9916 - val_loss: 29.4429\n",
      "Epoch 635/2000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 30.3992 - val_loss: 29.3156\n",
      "Epoch 636/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 42.6794 - val_loss: 29.1876\n",
      "Epoch 637/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 37.3336 - val_loss: 29.0595\n",
      "Epoch 638/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 35.1578 - val_loss: 28.9317\n",
      "Epoch 639/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 33.6170 - val_loss: 28.8044\n",
      "Epoch 640/2000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 34.4614 - val_loss: 28.6772\n",
      "Epoch 641/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 36.8553 - val_loss: 28.5504\n",
      "Epoch 642/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 34.9656 - val_loss: 28.4239\n",
      "Epoch 643/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 33.4935 - val_loss: 28.2986\n",
      "Epoch 644/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 37.7045 - val_loss: 28.1729\n",
      "Epoch 645/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 29.4298 - val_loss: 28.0485\n",
      "Epoch 646/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 30.2290 - val_loss: 27.9246\n",
      "Epoch 647/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 26.4419 - val_loss: 27.8019\n",
      "Epoch 648/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 28.6663 - val_loss: 27.6803\n",
      "Epoch 649/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 39.8126 - val_loss: 27.5582\n",
      "Epoch 650/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 29.7903 - val_loss: 27.4364\n",
      "Epoch 651/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 49.9169 - val_loss: 27.3134\n",
      "Epoch 652/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 29.2808 - val_loss: 27.1913\n",
      "Epoch 653/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 28.9416 - val_loss: 27.0697\n",
      "Epoch 654/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 38.3977 - val_loss: 26.9478\n",
      "Epoch 655/2000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 29.9468 - val_loss: 26.8265\n",
      "Epoch 656/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 33.4103 - val_loss: 26.7057\n",
      "Epoch 657/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 32.3140 - val_loss: 26.5857\n",
      "Epoch 658/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 30.5953 - val_loss: 26.4664\n",
      "Epoch 659/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 24.9961 - val_loss: 26.3485\n",
      "Epoch 660/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 30.3831 - val_loss: 26.2314\n",
      "Epoch 661/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 33.6673 - val_loss: 26.1143\n",
      "Epoch 662/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 35.0458 - val_loss: 25.9969\n",
      "Epoch 663/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 34.3690 - val_loss: 25.8797\n",
      "Epoch 664/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 28.6837 - val_loss: 25.7633\n",
      "Epoch 665/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 29.9146 - val_loss: 25.6474\n",
      "Epoch 666/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 25.7315 - val_loss: 25.5327\n",
      "Epoch 667/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 23.1528 - val_loss: 25.4192\n",
      "Epoch 668/2000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 32.6023 - val_loss: 25.3055\n",
      "Epoch 669/2000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 37.5806 - val_loss: 25.1917\n",
      "Epoch 670/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 29.4419 - val_loss: 25.0789\n",
      "Epoch 671/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 26.2315 - val_loss: 24.9670\n",
      "Epoch 672/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 28.6830 - val_loss: 24.8560\n",
      "Epoch 673/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 33.6278 - val_loss: 24.7453\n",
      "Epoch 674/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 30.4708 - val_loss: 24.6344\n",
      "Epoch 675/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 23.0259 - val_loss: 24.5251\n",
      "Epoch 676/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 35.5633 - val_loss: 24.4151\n",
      "Epoch 677/2000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 27.7226 - val_loss: 24.3061\n",
      "Epoch 678/2000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 33.2681 - val_loss: 24.1971\n",
      "Epoch 679/2000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 37.0920 - val_loss: 24.0876\n",
      "Epoch 680/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 38.8550 - val_loss: 23.9784\n",
      "Epoch 681/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 38.2149 - val_loss: 23.8688\n",
      "Epoch 682/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 30.1514 - val_loss: 23.7595\n",
      "Epoch 683/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 39.0832 - val_loss: 23.6493\n",
      "Epoch 684/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 36.4315 - val_loss: 23.5390\n",
      "Epoch 685/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 32.4282 - val_loss: 23.4295\n",
      "Epoch 686/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 34.3446 - val_loss: 23.3197\n",
      "Epoch 687/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 32.8174 - val_loss: 23.2101\n",
      "Epoch 688/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 30.7709 - val_loss: 23.1009\n",
      "Epoch 689/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 36.2450 - val_loss: 22.9920\n",
      "Epoch 690/2000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 39.6057 - val_loss: 22.8829\n",
      "Epoch 691/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 22.9552 - val_loss: 22.7754\n",
      "Epoch 692/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 25.2331 - val_loss: 22.6692\n",
      "Epoch 693/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 28.7053 - val_loss: 22.5637\n",
      "Epoch 694/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 25.5032 - val_loss: 22.4589\n",
      "Epoch 695/2000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 32.5275 - val_loss: 22.3536\n",
      "Epoch 696/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 29.2092 - val_loss: 22.2488\n",
      "Epoch 697/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 30.9940 - val_loss: 22.1440\n",
      "Epoch 698/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 29.6994 - val_loss: 22.0403\n",
      "Epoch 699/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 24.2781 - val_loss: 21.9378\n",
      "Epoch 700/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 25.0024 - val_loss: 21.8362\n",
      "Epoch 701/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 27.4284 - val_loss: 21.7350\n",
      "Epoch 702/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 26.7291 - val_loss: 21.6345\n",
      "Epoch 703/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 25.7342 - val_loss: 21.5346\n",
      "Epoch 704/2000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 27.9548 - val_loss: 21.4355\n",
      "Epoch 705/2000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 34.4056 - val_loss: 21.3366\n",
      "Epoch 706/2000\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 39.1615 - val_loss: 21.2364\n",
      "Epoch 707/2000\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 25.8587 - val_loss: 21.1373\n",
      "Epoch 708/2000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 31.7664 - val_loss: 21.0377\n",
      "Epoch 709/2000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 21.2597 - val_loss: 20.9397\n",
      "Epoch 710/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 22.6263 - val_loss: 20.8434\n",
      "Epoch 711/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 20.4027 - val_loss: 20.7490\n",
      "Epoch 712/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 24.8911 - val_loss: 20.6549\n",
      "Epoch 713/2000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 27.0870 - val_loss: 20.5617\n",
      "Epoch 714/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 24.7125 - val_loss: 20.4689\n",
      "Epoch 715/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 25.2609 - val_loss: 20.3760\n",
      "Epoch 716/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 20.3355 - val_loss: 20.2843\n",
      "Epoch 717/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 23.5796 - val_loss: 20.1931\n",
      "Epoch 718/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 25.7000 - val_loss: 20.1030\n",
      "Epoch 719/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 32.0720 - val_loss: 20.0123\n",
      "Epoch 720/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 25.7140 - val_loss: 19.9221\n",
      "Epoch 721/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 30.3660 - val_loss: 19.8315\n",
      "Epoch 722/2000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 27.9633 - val_loss: 19.7411\n",
      "Epoch 723/2000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 28.8032 - val_loss: 19.6503\n",
      "Epoch 724/2000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 26.4561 - val_loss: 19.5600\n",
      "Epoch 725/2000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 30.2726 - val_loss: 19.4694\n",
      "Epoch 726/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 27.3943 - val_loss: 19.3791\n",
      "Epoch 727/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 26.2466 - val_loss: 19.2890\n",
      "Epoch 728/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 27.0338 - val_loss: 19.1993\n",
      "Epoch 729/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 22.4159 - val_loss: 19.1105\n",
      "Epoch 730/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 28.9527 - val_loss: 19.0220\n",
      "Epoch 731/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 22.3891 - val_loss: 18.9346\n",
      "Epoch 732/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 17.3008 - val_loss: 18.8486\n",
      "Epoch 733/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 26.3040 - val_loss: 18.7629\n",
      "Epoch 734/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 31.1108 - val_loss: 18.6762\n",
      "Epoch 735/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 22.7961 - val_loss: 18.5899\n",
      "Epoch 736/2000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 23.8827 - val_loss: 18.5041\n",
      "Epoch 737/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 24.8986 - val_loss: 18.4186\n",
      "Epoch 738/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 29.5953 - val_loss: 18.3321\n",
      "Epoch 739/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 20.1332 - val_loss: 18.2468\n",
      "Epoch 740/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 19.1766 - val_loss: 18.1625\n",
      "Epoch 741/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 23.3030 - val_loss: 18.0784\n",
      "Epoch 742/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 21.7930 - val_loss: 17.9944\n",
      "Epoch 743/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 22.3628 - val_loss: 17.9110\n",
      "Epoch 744/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 23.7088 - val_loss: 17.8284\n",
      "Epoch 745/2000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 20.7732 - val_loss: 17.7470\n",
      "Epoch 746/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 25.2060 - val_loss: 17.6655\n",
      "Epoch 747/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 24.0878 - val_loss: 17.5834\n",
      "Epoch 748/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 18.3557 - val_loss: 17.5022\n",
      "Epoch 749/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 18.3437 - val_loss: 17.4231\n",
      "Epoch 750/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 21.4520 - val_loss: 17.3444\n",
      "Epoch 751/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 23.5614 - val_loss: 17.2664\n",
      "Epoch 752/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 25.1981 - val_loss: 17.1882\n",
      "Epoch 753/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 21.0237 - val_loss: 17.1108\n",
      "Epoch 754/2000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 22.8390 - val_loss: 17.0340\n",
      "Epoch 755/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 19.0936 - val_loss: 16.9579\n",
      "Epoch 756/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 21.3727 - val_loss: 16.8820\n",
      "Epoch 757/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 26.2260 - val_loss: 16.8053\n",
      "Epoch 758/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 27.6334 - val_loss: 16.7275\n",
      "Epoch 759/2000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 26.2276 - val_loss: 16.6494\n",
      "Epoch 760/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 22.4211 - val_loss: 16.5714\n",
      "Epoch 761/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 22.8504 - val_loss: 16.4937\n",
      "Epoch 762/2000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 12.3202 - val_loss: 16.4187\n",
      "Epoch 763/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 18.9163 - val_loss: 16.3439\n",
      "Epoch 764/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 28.8151 - val_loss: 16.2682\n",
      "Epoch 765/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 17.7361 - val_loss: 16.1930\n",
      "Epoch 766/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 25.9453 - val_loss: 16.1173\n",
      "Epoch 767/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 26.9096 - val_loss: 16.0411\n",
      "Epoch 768/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 17.1054 - val_loss: 15.9662\n",
      "Epoch 769/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 23.1773 - val_loss: 15.8908\n",
      "Epoch 770/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 14.0943 - val_loss: 15.8171\n",
      "Epoch 771/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 26.8712 - val_loss: 15.7423\n",
      "Epoch 772/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 17.0197 - val_loss: 15.6683\n",
      "Epoch 773/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 19.8457 - val_loss: 15.5948\n",
      "Epoch 774/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 28.2822 - val_loss: 15.5205\n",
      "Epoch 775/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 22.6623 - val_loss: 15.4468\n",
      "Epoch 776/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 24.5427 - val_loss: 15.3726\n",
      "Epoch 777/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 29.5797 - val_loss: 15.2978\n",
      "Epoch 778/2000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 24.3220 - val_loss: 15.2230\n",
      "Epoch 779/2000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 24.9660 - val_loss: 15.1484\n",
      "Epoch 780/2000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 16.8223 - val_loss: 15.0746\n",
      "Epoch 781/2000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 19.4382 - val_loss: 15.0012\n",
      "Epoch 782/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 19.1279 - val_loss: 14.9287\n",
      "Epoch 783/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 22.1757 - val_loss: 14.8566\n",
      "Epoch 784/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 25.0202 - val_loss: 14.7850\n",
      "Epoch 785/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 17.0537 - val_loss: 14.7145\n",
      "Epoch 786/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 13.9904 - val_loss: 14.6452\n",
      "Epoch 787/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 16.5140 - val_loss: 14.5768\n",
      "Epoch 788/2000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 18.8602 - val_loss: 14.5082\n",
      "Epoch 789/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 24.8410 - val_loss: 14.4390\n",
      "Epoch 790/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 29.6921 - val_loss: 14.3693\n",
      "Epoch 791/2000\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 21.3751 - val_loss: 14.2998\n",
      "Epoch 792/2000\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 17.8447 - val_loss: 14.2309\n",
      "Epoch 793/2000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 17.9228 - val_loss: 14.1631\n",
      "Epoch 794/2000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 19.2150 - val_loss: 14.0955\n",
      "Epoch 795/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 14.5476 - val_loss: 14.0294\n",
      "Epoch 796/2000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 15.0434 - val_loss: 13.9636\n",
      "Epoch 797/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 18.7614 - val_loss: 13.8983\n",
      "Epoch 798/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 20.1954 - val_loss: 13.8335\n",
      "Epoch 799/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 19.5435 - val_loss: 13.7690\n",
      "Epoch 800/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 18.4945 - val_loss: 13.7046\n",
      "Epoch 801/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 15.6266 - val_loss: 13.6405\n",
      "Epoch 802/2000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 21.9650 - val_loss: 13.5772\n",
      "Epoch 803/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 25.1430 - val_loss: 13.5136\n",
      "Epoch 804/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 14.1596 - val_loss: 13.4507\n",
      "Epoch 805/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 15.2962 - val_loss: 13.3882\n",
      "Epoch 806/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 22.0115 - val_loss: 13.3267\n",
      "Epoch 807/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 16.5155 - val_loss: 13.2660\n",
      "Epoch 808/2000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 23.7248 - val_loss: 13.2041\n",
      "Epoch 809/2000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 19.5391 - val_loss: 13.1422\n",
      "Epoch 810/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 15.3446 - val_loss: 13.0814\n",
      "Epoch 811/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 19.4223 - val_loss: 13.0202\n",
      "Epoch 812/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 16.5886 - val_loss: 12.9590\n",
      "Epoch 813/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 20.4438 - val_loss: 12.8974\n",
      "Epoch 814/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 21.8044 - val_loss: 12.8358\n",
      "Epoch 815/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 19.4599 - val_loss: 12.7752\n",
      "Epoch 816/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 13.4662 - val_loss: 12.7156\n",
      "Epoch 817/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 15.0741 - val_loss: 12.6575\n",
      "Epoch 818/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 12.8118 - val_loss: 12.6009\n",
      "Epoch 819/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 12.4874 - val_loss: 12.5450\n",
      "Epoch 820/2000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 18.7128 - val_loss: 12.4894\n",
      "Epoch 821/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 16.3805 - val_loss: 12.4336\n",
      "Epoch 822/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 17.7887 - val_loss: 12.3776\n",
      "Epoch 823/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 18.4975 - val_loss: 12.3214\n",
      "Epoch 824/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 14.0380 - val_loss: 12.2657\n",
      "Epoch 825/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 17.4597 - val_loss: 12.2106\n",
      "Epoch 826/2000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 13.6552 - val_loss: 12.1558\n",
      "Epoch 827/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 22.8097 - val_loss: 12.1006\n",
      "Epoch 828/2000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 17.5734 - val_loss: 12.0455\n",
      "Epoch 829/2000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 18.6782 - val_loss: 11.9907\n",
      "Epoch 830/2000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 25.0810 - val_loss: 11.9352\n",
      "Epoch 831/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 18.7494 - val_loss: 11.8795\n",
      "Epoch 832/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 15.4206 - val_loss: 11.8237\n",
      "Epoch 833/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 12.6983 - val_loss: 11.7684\n",
      "Epoch 834/2000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 13.3195 - val_loss: 11.7137\n",
      "Epoch 835/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 15.2302 - val_loss: 11.6589\n",
      "Epoch 836/2000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 14.2672 - val_loss: 11.6050\n",
      "Epoch 837/2000\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 8.8523 - val_loss: 11.5526\n",
      "Epoch 838/2000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 12.5704 - val_loss: 11.5009\n",
      "Epoch 839/2000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 12.0815 - val_loss: 11.4492\n",
      "Epoch 840/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 17.6398 - val_loss: 11.3971\n",
      "Epoch 841/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 20.8155 - val_loss: 11.3448\n",
      "Epoch 842/2000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 21.8242 - val_loss: 11.2916\n",
      "Epoch 843/2000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 13.8687 - val_loss: 11.2388\n",
      "Epoch 844/2000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 22.0123 - val_loss: 11.1856\n",
      "Epoch 845/2000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 12.7767 - val_loss: 11.1327\n",
      "Epoch 846/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 19.9520 - val_loss: 11.0794\n",
      "Epoch 847/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 19.4355 - val_loss: 11.0259\n",
      "Epoch 848/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 17.9287 - val_loss: 10.9727\n",
      "Epoch 849/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 22.8098 - val_loss: 10.9189\n",
      "Epoch 850/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 17.0169 - val_loss: 10.8661\n",
      "Epoch 851/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 19.6092 - val_loss: 10.8129\n",
      "Epoch 852/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 14.3898 - val_loss: 10.7605\n",
      "Epoch 853/2000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 15.4887 - val_loss: 10.7085\n",
      "Epoch 854/2000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 9.7856 - val_loss: 10.6573\n",
      "Epoch 855/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 14.5169 - val_loss: 10.6059\n",
      "Epoch 856/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 20.0025 - val_loss: 10.5545\n",
      "Epoch 857/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 17.9515 - val_loss: 10.5035\n",
      "Epoch 858/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 14.0908 - val_loss: 10.4531\n",
      "Epoch 859/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 16.3718 - val_loss: 10.4035\n",
      "Epoch 860/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 10.0953 - val_loss: 10.3548\n",
      "Epoch 861/2000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 14.7377 - val_loss: 10.3063\n",
      "Epoch 862/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 10.4643 - val_loss: 10.2589\n",
      "Epoch 863/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 9.5136 - val_loss: 10.2122\n",
      "Epoch 864/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 12.7000 - val_loss: 10.1657\n",
      "Epoch 865/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 17.2493 - val_loss: 10.1189\n",
      "Epoch 866/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 21.9804 - val_loss: 10.0713\n",
      "Epoch 867/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 11.9827 - val_loss: 10.0251\n",
      "Epoch 868/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 24.1123 - val_loss: 9.9775\n",
      "Epoch 869/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 15.9138 - val_loss: 9.9296\n",
      "Epoch 870/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 16.7582 - val_loss: 9.8822\n",
      "Epoch 871/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 18.9990 - val_loss: 9.8362\n",
      "Epoch 872/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 8.4680 - val_loss: 9.7912\n",
      "Epoch 873/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 14.1996 - val_loss: 9.7465\n",
      "Epoch 874/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 12.9662 - val_loss: 9.7022\n",
      "Epoch 875/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 12.4242 - val_loss: 9.6580\n",
      "Epoch 876/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 11.6422 - val_loss: 9.6141\n",
      "Epoch 877/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 14.9339 - val_loss: 9.5699\n",
      "Epoch 878/2000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 14.5731 - val_loss: 9.5256\n",
      "Epoch 879/2000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 9.5460 - val_loss: 9.4821\n",
      "Epoch 880/2000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 10.9149 - val_loss: 9.4386\n",
      "Epoch 881/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 13.6921 - val_loss: 9.3954\n",
      "Epoch 882/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 13.7715 - val_loss: 9.3530\n",
      "Epoch 883/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 16.3963 - val_loss: 9.3105\n",
      "Epoch 884/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 13.4318 - val_loss: 9.2674\n",
      "Epoch 885/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 13.8258 - val_loss: 9.2252\n",
      "Epoch 886/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 17.8646 - val_loss: 9.1830\n",
      "Epoch 887/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 16.1619 - val_loss: 9.1405\n",
      "Epoch 888/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 20.0881 - val_loss: 9.0973\n",
      "Epoch 889/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 12.2836 - val_loss: 9.0557\n",
      "Epoch 890/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 11.0670 - val_loss: 9.0147\n",
      "Epoch 891/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 11.2662 - val_loss: 8.9740\n",
      "Epoch 892/2000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 11.1654 - val_loss: 8.9338\n",
      "Epoch 893/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 17.8665 - val_loss: 8.8927\n",
      "Epoch 894/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 15.6883 - val_loss: 8.8518\n",
      "Epoch 895/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 16.7477 - val_loss: 8.8111\n",
      "Epoch 896/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 17.6696 - val_loss: 8.7696\n",
      "Epoch 897/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 12.1661 - val_loss: 8.7284\n",
      "Epoch 898/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 14.4647 - val_loss: 8.6868\n",
      "Epoch 899/2000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 11.8221 - val_loss: 8.6460\n",
      "Epoch 900/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 17.0842 - val_loss: 8.6046\n",
      "Epoch 901/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 10.4907 - val_loss: 8.5641\n",
      "Epoch 902/2000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 13.0280 - val_loss: 8.5244\n",
      "Epoch 903/2000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 7.4909 - val_loss: 8.4858\n",
      "Epoch 904/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 14.3897 - val_loss: 8.4469\n",
      "Epoch 905/2000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 9.5099 - val_loss: 8.4092\n",
      "Epoch 906/2000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 13.0007 - val_loss: 8.3712\n",
      "Epoch 907/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 9.5544 - val_loss: 8.3347\n",
      "Epoch 908/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 15.6763 - val_loss: 8.2974\n",
      "Epoch 909/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 14.6203 - val_loss: 8.2593\n",
      "Epoch 910/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 13.1617 - val_loss: 8.2211\n",
      "Epoch 911/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 9.5735 - val_loss: 8.1831\n",
      "Epoch 912/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 13.8905 - val_loss: 8.1448\n",
      "Epoch 913/2000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 12.0292 - val_loss: 8.1064\n",
      "Epoch 914/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 18.1794 - val_loss: 8.0675\n",
      "Epoch 915/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 12.0890 - val_loss: 8.0289\n",
      "Epoch 916/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 7.3787 - val_loss: 7.9917\n",
      "Epoch 917/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 9.8336 - val_loss: 7.9553\n",
      "Epoch 918/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 19.1764 - val_loss: 7.9179\n",
      "Epoch 919/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 10.5363 - val_loss: 7.8810\n",
      "Epoch 920/2000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 8.6246 - val_loss: 7.8453\n",
      "Epoch 921/2000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 11.8638 - val_loss: 7.8094\n",
      "Epoch 922/2000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 11.3894 - val_loss: 7.7742\n",
      "Epoch 923/2000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 11.6250 - val_loss: 7.7395\n",
      "Epoch 924/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 10.7811 - val_loss: 7.7047\n",
      "Epoch 925/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 10.6855 - val_loss: 7.6703\n",
      "Epoch 926/2000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 11.5895 - val_loss: 7.6367\n",
      "Epoch 927/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 13.0776 - val_loss: 7.6038\n",
      "Epoch 928/2000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 11.0467 - val_loss: 7.5713\n",
      "Epoch 929/2000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 11.5189 - val_loss: 7.5389\n",
      "Epoch 930/2000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 9.9056 - val_loss: 7.5071\n",
      "Epoch 931/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 16.9825 - val_loss: 7.4748\n",
      "Epoch 932/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 7.2608 - val_loss: 7.4433\n",
      "Epoch 933/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 18.8547 - val_loss: 7.4108\n",
      "Epoch 934/2000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 11.6678 - val_loss: 7.3780\n",
      "Epoch 935/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 8.3485 - val_loss: 7.3462\n",
      "Epoch 936/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 9.1090 - val_loss: 7.3142\n",
      "Epoch 937/2000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 15.0834 - val_loss: 7.2816\n",
      "Epoch 938/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 6.0973 - val_loss: 7.2496\n",
      "Epoch 939/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 12.5430 - val_loss: 7.2172\n",
      "Epoch 940/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 12.7234 - val_loss: 7.1856\n",
      "Epoch 941/2000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 9.7596 - val_loss: 7.1541\n",
      "Epoch 942/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 18.0146 - val_loss: 7.1219\n",
      "Epoch 943/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 17.4485 - val_loss: 7.0889\n",
      "Epoch 944/2000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 8.1995 - val_loss: 7.0564\n",
      "Epoch 945/2000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 11.7200 - val_loss: 7.0238\n",
      "Epoch 946/2000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 15.3528 - val_loss: 6.9913\n",
      "Epoch 947/2000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 5.8762 - val_loss: 6.9603\n",
      "Epoch 948/2000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 6.2819 - val_loss: 6.9302\n",
      "Epoch 949/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 9.1270 - val_loss: 6.9007\n",
      "Epoch 950/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 14.7527 - val_loss: 6.8701\n",
      "Epoch 951/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 17.0325 - val_loss: 6.8396\n",
      "Epoch 952/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 11.1935 - val_loss: 6.8084\n",
      "Epoch 953/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 8.3123 - val_loss: 6.7777\n",
      "Epoch 954/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 9.1155 - val_loss: 6.7476\n",
      "Epoch 955/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 13.0360 - val_loss: 6.7180\n",
      "Epoch 956/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 18.1983 - val_loss: 6.6872\n",
      "Epoch 957/2000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 13.6499 - val_loss: 6.6560\n",
      "Epoch 958/2000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 14.3371 - val_loss: 6.6245\n",
      "Epoch 959/2000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 14.0490 - val_loss: 6.5937\n",
      "Epoch 960/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 6.4979 - val_loss: 6.5639\n",
      "Epoch 961/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 12.8985 - val_loss: 6.5341\n",
      "Epoch 962/2000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 11.2661 - val_loss: 6.5050\n",
      "Epoch 963/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 15.1855 - val_loss: 6.4756\n",
      "Epoch 964/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 13.1979 - val_loss: 6.4461\n",
      "Epoch 965/2000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 9.9572 - val_loss: 6.4162\n",
      "Epoch 966/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 7.3380 - val_loss: 6.3877\n",
      "Epoch 967/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 9.3656 - val_loss: 6.3591\n",
      "Epoch 968/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 8.0703 - val_loss: 6.3313\n",
      "Epoch 969/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 10.5995 - val_loss: 6.3038\n",
      "Epoch 970/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 10.4383 - val_loss: 6.2763\n",
      "Epoch 971/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 10.0083 - val_loss: 6.2493\n",
      "Epoch 972/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 16.1146 - val_loss: 6.2214\n",
      "Epoch 973/2000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 10.4573 - val_loss: 6.1937\n",
      "Epoch 974/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 14.9973 - val_loss: 6.1652\n",
      "Epoch 975/2000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 7.5895 - val_loss: 6.1376\n",
      "Epoch 976/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 11.1032 - val_loss: 6.1102\n",
      "Epoch 977/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 8.0950 - val_loss: 6.0837\n",
      "Epoch 978/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 9.5628 - val_loss: 6.0569\n",
      "Epoch 979/2000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 11.1417 - val_loss: 6.0298\n",
      "Epoch 980/2000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 12.8573 - val_loss: 6.0036\n",
      "Epoch 981/2000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 10.1709 - val_loss: 5.9776\n",
      "Epoch 982/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 9.0998 - val_loss: 5.9511\n",
      "Epoch 983/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 15.5351 - val_loss: 5.9240\n",
      "Epoch 984/2000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 8.4243 - val_loss: 5.8972\n",
      "Epoch 985/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 16.8530 - val_loss: 5.8701\n",
      "Epoch 986/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 11.3224 - val_loss: 5.8432\n",
      "Epoch 987/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 10.6648 - val_loss: 5.8169\n",
      "Epoch 988/2000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 6.6531 - val_loss: 5.7917\n",
      "Epoch 989/2000\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 19.5101 - val_loss: 5.7668\n",
      "Epoch 990/2000\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 9.0200 - val_loss: 5.7417\n",
      "Epoch 991/2000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 7.0509 - val_loss: 5.7173\n",
      "Epoch 992/2000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 10.4608 - val_loss: 5.6929\n",
      "Epoch 993/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 14.6730 - val_loss: 5.6681\n",
      "Epoch 994/2000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 7.9798 - val_loss: 5.6438\n",
      "Epoch 995/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 9.3863 - val_loss: 5.6200\n",
      "Epoch 996/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.4263 - val_loss: 5.5969\n",
      "Epoch 997/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 10.6407 - val_loss: 5.5736\n",
      "Epoch 998/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 5.8701 - val_loss: 5.5516\n",
      "Epoch 999/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 7.9648 - val_loss: 5.5293\n",
      "Epoch 1000/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 10.2068 - val_loss: 5.5067\n",
      "Epoch 1001/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 15.4068 - val_loss: 5.4830\n",
      "Epoch 1002/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 8.7125 - val_loss: 5.4593\n",
      "Epoch 1003/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 13.6043 - val_loss: 5.4353\n",
      "Epoch 1004/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 10.6729 - val_loss: 5.4116\n",
      "Epoch 1005/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 7.8074 - val_loss: 5.3894\n",
      "Epoch 1006/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 9.6381 - val_loss: 5.3671\n",
      "Epoch 1007/2000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 9.9357 - val_loss: 5.3454\n",
      "Epoch 1008/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 7.5665 - val_loss: 5.3237\n",
      "Epoch 1009/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 10.9779 - val_loss: 5.3017\n",
      "Epoch 1010/2000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 6.9329 - val_loss: 5.2797\n",
      "Epoch 1011/2000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 9.2024 - val_loss: 5.2578\n",
      "Epoch 1012/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 9.7136 - val_loss: 5.2363\n",
      "Epoch 1013/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 10.9741 - val_loss: 5.2147\n",
      "Epoch 1014/2000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 6.3826 - val_loss: 5.1938\n",
      "Epoch 1015/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 11.9607 - val_loss: 5.1722\n",
      "Epoch 1016/2000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 7.1634 - val_loss: 5.1511\n",
      "Epoch 1017/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 13.6208 - val_loss: 5.1289\n",
      "Epoch 1018/2000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 14.5733 - val_loss: 5.1060\n",
      "Epoch 1019/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.4594 - val_loss: 5.0836\n",
      "Epoch 1020/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 13.0272 - val_loss: 5.0612\n",
      "Epoch 1021/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 11.0064 - val_loss: 5.0390\n",
      "Epoch 1022/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 11.7502 - val_loss: 5.0173\n",
      "Epoch 1023/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 13.4860 - val_loss: 4.9952\n",
      "Epoch 1024/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 13.4212 - val_loss: 4.9734\n",
      "Epoch 1025/2000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 7.6432 - val_loss: 4.9515\n",
      "Epoch 1026/2000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 9.7128 - val_loss: 4.9307\n",
      "Epoch 1027/2000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 8.9390 - val_loss: 4.9106\n",
      "Epoch 1028/2000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 9.6895 - val_loss: 4.8899\n",
      "Epoch 1029/2000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 6.4099 - val_loss: 4.8699\n",
      "Epoch 1030/2000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 11.2688 - val_loss: 4.8500\n",
      "Epoch 1031/2000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 11.2507 - val_loss: 4.8301\n",
      "Epoch 1032/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 10.2978 - val_loss: 4.8101\n",
      "Epoch 1033/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 10.8964 - val_loss: 4.7903\n",
      "Epoch 1034/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 11.3012 - val_loss: 4.7703\n",
      "Epoch 1035/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 7.0575 - val_loss: 4.7504\n",
      "Epoch 1036/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 11.2052 - val_loss: 4.7307\n",
      "Epoch 1037/2000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 10.5945 - val_loss: 4.7110\n",
      "Epoch 1038/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 10.0887 - val_loss: 4.6910\n",
      "Epoch 1039/2000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 15.8211 - val_loss: 4.6702\n",
      "Epoch 1040/2000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 9.5869 - val_loss: 4.6497\n",
      "Epoch 1041/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.0814 - val_loss: 4.6303\n",
      "Epoch 1042/2000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 7.7406 - val_loss: 4.6107\n",
      "Epoch 1043/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 7.1717 - val_loss: 4.5917\n",
      "Epoch 1044/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.5454 - val_loss: 4.5726\n",
      "Epoch 1045/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.7517 - val_loss: 4.5549\n",
      "Epoch 1046/2000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 8.1389 - val_loss: 4.5377\n",
      "Epoch 1047/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.8747 - val_loss: 4.5208\n",
      "Epoch 1048/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.8376 - val_loss: 4.5051\n",
      "Epoch 1049/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 7.1399 - val_loss: 4.4899\n",
      "Epoch 1050/2000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 7.0450 - val_loss: 4.4751\n",
      "Epoch 1051/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 7.6812 - val_loss: 4.4604\n",
      "Epoch 1052/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.2236 - val_loss: 4.4457\n",
      "Epoch 1053/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 10.3227 - val_loss: 4.4305\n",
      "Epoch 1054/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 8.8809 - val_loss: 4.4148\n",
      "Epoch 1055/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 7.7775 - val_loss: 4.3989\n",
      "Epoch 1056/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 8.0945 - val_loss: 4.3827\n",
      "Epoch 1057/2000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 10.2272 - val_loss: 4.3664\n",
      "Epoch 1058/2000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 9.6910 - val_loss: 4.3495\n",
      "Epoch 1059/2000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 7.1388 - val_loss: 4.3335\n",
      "Epoch 1060/2000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 7.2633 - val_loss: 4.3183\n",
      "Epoch 1061/2000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 7.6617 - val_loss: 4.3031\n",
      "Epoch 1062/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 10.2451 - val_loss: 4.2883\n",
      "Epoch 1063/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 8.0834 - val_loss: 4.2738\n",
      "Epoch 1064/2000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 13.4675 - val_loss: 4.2588\n",
      "Epoch 1065/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 11.6105 - val_loss: 4.2434\n",
      "Epoch 1066/2000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 6.7841 - val_loss: 4.2279\n",
      "Epoch 1067/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 11.0420 - val_loss: 4.2118\n",
      "Epoch 1068/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 11.2497 - val_loss: 4.1958\n",
      "Epoch 1069/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 9.1873 - val_loss: 4.1797\n",
      "Epoch 1070/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 8.3683 - val_loss: 4.1637\n",
      "Epoch 1071/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 16.5963 - val_loss: 4.1475\n",
      "Epoch 1072/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.8706 - val_loss: 4.1316\n",
      "Epoch 1073/2000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 10.5439 - val_loss: 4.1158\n",
      "Epoch 1074/2000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 4.3589 - val_loss: 4.1005\n",
      "Epoch 1075/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.1037 - val_loss: 4.0856\n",
      "Epoch 1076/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 9.0919 - val_loss: 4.0704\n",
      "Epoch 1077/2000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 6.8242 - val_loss: 4.0560\n",
      "Epoch 1078/2000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 5.3615 - val_loss: 4.0421\n",
      "Epoch 1079/2000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 6.6637 - val_loss: 4.0283\n",
      "Epoch 1080/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 6.0966 - val_loss: 4.0148\n",
      "Epoch 1081/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 7.9851 - val_loss: 4.0012\n",
      "Epoch 1082/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 12.7953 - val_loss: 3.9869\n",
      "Epoch 1083/2000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 6.3708 - val_loss: 3.9723\n",
      "Epoch 1084/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 10.7885 - val_loss: 3.9569\n",
      "Epoch 1085/2000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 10.8713 - val_loss: 3.9412\n",
      "Epoch 1086/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 15.9013 - val_loss: 3.9253\n",
      "Epoch 1087/2000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 8.8255 - val_loss: 3.9097\n",
      "Epoch 1088/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 9.0505 - val_loss: 3.8946\n",
      "Epoch 1089/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 7.3148 - val_loss: 3.8803\n",
      "Epoch 1090/2000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 13.7844 - val_loss: 3.8657\n",
      "Epoch 1091/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.6951 - val_loss: 3.8516\n",
      "Epoch 1092/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.8777 - val_loss: 3.8382\n",
      "Epoch 1093/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 6.9570 - val_loss: 3.8243\n",
      "Epoch 1094/2000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 7.1163 - val_loss: 3.8106\n",
      "Epoch 1095/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 9.0018 - val_loss: 3.7973\n",
      "Epoch 1096/2000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 11.2294 - val_loss: 3.7833\n",
      "Epoch 1097/2000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.4851 - val_loss: 3.7698\n",
      "Epoch 1098/2000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 11.4184 - val_loss: 3.7560\n",
      "Epoch 1099/2000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 9.4543 - val_loss: 3.7422\n",
      "Epoch 1100/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 9.8452 - val_loss: 3.7283\n",
      "Epoch 1101/2000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 8.2910 - val_loss: 3.7144\n",
      "Epoch 1102/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 6.3915 - val_loss: 3.7014\n",
      "Epoch 1103/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 12.6255 - val_loss: 3.6878\n",
      "Epoch 1104/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 14.4758 - val_loss: 3.6736\n",
      "Epoch 1105/2000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 7.4538 - val_loss: 3.6594\n",
      "Epoch 1106/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.7106 - val_loss: 3.6459\n",
      "Epoch 1107/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 7.8659 - val_loss: 3.6320\n",
      "Epoch 1108/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 8.6098 - val_loss: 3.6182\n",
      "Epoch 1109/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 8.1934 - val_loss: 3.6045\n",
      "Epoch 1110/2000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 7.1734 - val_loss: 3.5915\n",
      "Epoch 1111/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.7644 - val_loss: 3.5786\n",
      "Epoch 1112/2000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 6.2432 - val_loss: 3.5657\n",
      "Epoch 1113/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.8486 - val_loss: 3.5534\n",
      "Epoch 1114/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 11.0670 - val_loss: 3.5406\n",
      "Epoch 1115/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.7537 - val_loss: 3.5286\n",
      "Epoch 1116/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 2.6082 - val_loss: 3.5178\n",
      "Epoch 1117/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 13.9247 - val_loss: 3.5055\n",
      "Epoch 1118/2000\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 6.7784 - val_loss: 3.4937\n",
      "Epoch 1119/2000\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 8.1398 - val_loss: 3.4815\n",
      "Epoch 1120/2000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 9.7626 - val_loss: 3.4691\n",
      "Epoch 1121/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 7.0170 - val_loss: 3.4578\n",
      "Epoch 1122/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 5.2019 - val_loss: 3.4471\n",
      "Epoch 1123/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 10.2111 - val_loss: 3.4364\n",
      "Epoch 1124/2000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 10.7814 - val_loss: 3.4252\n",
      "Epoch 1125/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 8.2390 - val_loss: 3.4140\n",
      "Epoch 1126/2000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 15.4267 - val_loss: 3.4022\n",
      "Epoch 1127/2000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 7.9233 - val_loss: 3.3903\n",
      "Epoch 1128/2000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 9.8793 - val_loss: 3.3787\n",
      "Epoch 1129/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 15.4602 - val_loss: 3.3668\n",
      "Epoch 1130/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 12.4992 - val_loss: 3.3550\n",
      "Epoch 1131/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 9.6188 - val_loss: 3.3435\n",
      "Epoch 1132/2000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 10.1466 - val_loss: 3.3318\n",
      "Epoch 1133/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 6.7078 - val_loss: 3.3204\n",
      "Epoch 1134/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 7.6652 - val_loss: 3.3091\n",
      "Epoch 1135/2000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 7.5226 - val_loss: 3.2977\n",
      "Epoch 1136/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 7.5406 - val_loss: 3.2868\n",
      "Epoch 1137/2000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 9.8655 - val_loss: 3.2752\n",
      "Epoch 1138/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 9.8118 - val_loss: 3.2639\n",
      "Epoch 1139/2000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 8.7926 - val_loss: 3.2525\n",
      "Epoch 1140/2000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 3.1486 - val_loss: 3.2421\n",
      "Epoch 1141/2000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 11.1213 - val_loss: 3.2317\n",
      "Epoch 1142/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 10.5210 - val_loss: 3.2213\n",
      "Epoch 1143/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 8.1209 - val_loss: 3.2114\n",
      "Epoch 1144/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 6.5071 - val_loss: 3.2021\n",
      "Epoch 1145/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 7.1511 - val_loss: 3.1932\n",
      "Epoch 1146/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.7308 - val_loss: 3.1841\n",
      "Epoch 1147/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 7.9801 - val_loss: 3.1755\n",
      "Epoch 1148/2000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 8.4420 - val_loss: 3.1667\n",
      "Epoch 1149/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 6.1588 - val_loss: 3.1575\n",
      "Epoch 1150/2000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 7.8472 - val_loss: 3.1483\n",
      "Epoch 1151/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.1807 - val_loss: 3.1395\n",
      "Epoch 1152/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.8458 - val_loss: 3.1307\n",
      "Epoch 1153/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 9.7728 - val_loss: 3.1211\n",
      "Epoch 1154/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 6.3962 - val_loss: 3.1120\n",
      "Epoch 1155/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 10.9089 - val_loss: 3.1022\n",
      "Epoch 1156/2000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 6.7088 - val_loss: 3.0921\n",
      "Epoch 1157/2000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 7.8927 - val_loss: 3.0818\n",
      "Epoch 1158/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 11.6503 - val_loss: 3.0709\n",
      "Epoch 1159/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 10.6565 - val_loss: 3.0595\n",
      "Epoch 1160/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.2419 - val_loss: 3.0485\n",
      "Epoch 1161/2000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 7.4722 - val_loss: 3.0372\n",
      "Epoch 1162/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 12.3488 - val_loss: 3.0267\n",
      "Epoch 1163/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 11.1892 - val_loss: 3.0170\n",
      "Epoch 1164/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.4632 - val_loss: 3.0076\n",
      "Epoch 1165/2000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 11.3969 - val_loss: 2.9980\n",
      "Epoch 1166/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.5513 - val_loss: 2.9887\n",
      "Epoch 1167/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 7.7563 - val_loss: 2.9798\n",
      "Epoch 1168/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 3.8950 - val_loss: 2.9715\n",
      "Epoch 1169/2000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 13.6038 - val_loss: 2.9625\n",
      "Epoch 1170/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.5700 - val_loss: 2.9540\n",
      "Epoch 1171/2000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 7.4419 - val_loss: 2.9452\n",
      "Epoch 1172/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 3.1289 - val_loss: 2.9366\n",
      "Epoch 1173/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.4864 - val_loss: 2.9281\n",
      "Epoch 1174/2000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 11.7461 - val_loss: 2.9189\n",
      "Epoch 1175/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 6.1725 - val_loss: 2.9097\n",
      "Epoch 1176/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 7.6208 - val_loss: 2.9010\n",
      "Epoch 1177/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 9.6596 - val_loss: 2.8922\n",
      "Epoch 1178/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 3.3968 - val_loss: 2.8838\n",
      "Epoch 1179/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 6.2168 - val_loss: 2.8757\n",
      "Epoch 1180/2000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 10.7120 - val_loss: 2.8671\n",
      "Epoch 1181/2000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 11.6970 - val_loss: 2.8582\n",
      "Epoch 1182/2000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 7.2593 - val_loss: 2.8499\n",
      "Epoch 1183/2000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 6.0965 - val_loss: 2.8413\n",
      "Epoch 1184/2000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 9.6701 - val_loss: 2.8326\n",
      "Epoch 1185/2000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 10.3106 - val_loss: 2.8240\n",
      "Epoch 1186/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 6.5458 - val_loss: 2.8155\n",
      "Epoch 1187/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 11.0263 - val_loss: 2.8066\n",
      "Epoch 1188/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 10.2179 - val_loss: 2.7979\n",
      "Epoch 1189/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 6.5904 - val_loss: 2.7896\n",
      "Epoch 1190/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.9166 - val_loss: 2.7815\n",
      "Epoch 1191/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.2432 - val_loss: 2.7733\n",
      "Epoch 1192/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 6.3516 - val_loss: 2.7652\n",
      "Epoch 1193/2000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 7.5263 - val_loss: 2.7569\n",
      "Epoch 1194/2000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 7.3053 - val_loss: 2.7491\n",
      "Epoch 1195/2000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 10.4910 - val_loss: 2.7411\n",
      "Epoch 1196/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 14.0800 - val_loss: 2.7330\n",
      "Epoch 1197/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 12.3042 - val_loss: 2.7246\n",
      "Epoch 1198/2000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 7.1419 - val_loss: 2.7161\n",
      "Epoch 1199/2000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 9.4208 - val_loss: 2.7079\n",
      "Epoch 1200/2000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 12.4613 - val_loss: 2.6998\n",
      "Epoch 1201/2000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 7.8813 - val_loss: 2.6916\n",
      "Epoch 1202/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 6.3634 - val_loss: 2.6834\n",
      "Epoch 1203/2000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 7.9034 - val_loss: 2.6756\n",
      "Epoch 1204/2000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 13.6303 - val_loss: 2.6678\n",
      "Epoch 1205/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 3.4052 - val_loss: 2.6606\n",
      "Epoch 1206/2000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 9.6158 - val_loss: 2.6532\n",
      "Epoch 1207/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.5800 - val_loss: 2.6460\n",
      "Epoch 1208/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 9.3298 - val_loss: 2.6390\n",
      "Epoch 1209/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 7.2191 - val_loss: 2.6321\n",
      "Epoch 1210/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 6.8416 - val_loss: 2.6250\n",
      "Epoch 1211/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 14.1915 - val_loss: 2.6178\n",
      "Epoch 1212/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 10.8850 - val_loss: 2.6105\n",
      "Epoch 1213/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 2.7363 - val_loss: 2.6039\n",
      "Epoch 1214/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.0739 - val_loss: 2.5973\n",
      "Epoch 1215/2000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 7.3620 - val_loss: 2.5905\n",
      "Epoch 1216/2000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 4.5757 - val_loss: 2.5839\n",
      "Epoch 1217/2000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 4.2346 - val_loss: 2.5777\n",
      "Epoch 1218/2000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 5.2159 - val_loss: 2.5713\n",
      "Epoch 1219/2000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 10.6479 - val_loss: 2.5650\n",
      "Epoch 1220/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 6.6694 - val_loss: 2.5587\n",
      "Epoch 1221/2000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 10.1371 - val_loss: 2.5524\n",
      "Epoch 1222/2000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 4.5106 - val_loss: 2.5471\n",
      "Epoch 1223/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 6.5425 - val_loss: 2.5421\n",
      "Epoch 1224/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.6184 - val_loss: 2.5373\n",
      "Epoch 1225/2000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 6.7682 - val_loss: 2.5327\n",
      "Epoch 1226/2000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 3.1032 - val_loss: 2.5284\n",
      "Epoch 1227/2000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 6.4176 - val_loss: 2.5241\n",
      "Epoch 1228/2000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 7.5730 - val_loss: 2.5192\n",
      "Epoch 1229/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.4777 - val_loss: 2.5138\n",
      "Epoch 1230/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 9.9420 - val_loss: 2.5081\n",
      "Epoch 1231/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 7.8450 - val_loss: 2.5020\n",
      "Epoch 1232/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 8.0588 - val_loss: 2.4958\n",
      "Epoch 1233/2000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 7.5447 - val_loss: 2.4899\n",
      "Epoch 1234/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.7026 - val_loss: 2.4837\n",
      "Epoch 1235/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 8.7788 - val_loss: 2.4776\n",
      "Epoch 1236/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.8778 - val_loss: 2.4716\n",
      "Epoch 1237/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 9.0300 - val_loss: 2.4650\n",
      "Epoch 1238/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 12.1650 - val_loss: 2.4579\n",
      "Epoch 1239/2000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 11.1646 - val_loss: 2.4507\n",
      "Epoch 1240/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 7.9179 - val_loss: 2.4437\n",
      "Epoch 1241/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.1422 - val_loss: 2.4372\n",
      "Epoch 1242/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 2.5440 - val_loss: 2.4310\n",
      "Epoch 1243/2000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 4.9655 - val_loss: 2.4249\n",
      "Epoch 1244/2000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 6.9085 - val_loss: 2.4190\n",
      "Epoch 1245/2000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 7.9496 - val_loss: 2.4131\n",
      "Epoch 1246/2000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 8.5071 - val_loss: 2.4075\n",
      "Epoch 1247/2000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 4.5672 - val_loss: 2.4018\n",
      "Epoch 1248/2000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 7.3138 - val_loss: 2.3962\n",
      "Epoch 1249/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 6.2522 - val_loss: 2.3905\n",
      "Epoch 1250/2000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.3617 - val_loss: 2.3855\n",
      "Epoch 1251/2000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 4.3227 - val_loss: 2.3805\n",
      "Epoch 1252/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.4973 - val_loss: 2.3763\n",
      "Epoch 1253/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 9.2254 - val_loss: 2.3719\n",
      "Epoch 1254/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 7.7334 - val_loss: 2.3672\n",
      "Epoch 1255/2000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.2608 - val_loss: 2.3625\n",
      "Epoch 1256/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 6.5095 - val_loss: 2.3576\n",
      "Epoch 1257/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 9.0427 - val_loss: 2.3526\n",
      "Epoch 1258/2000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 8.6888 - val_loss: 2.3475\n",
      "Epoch 1259/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 15.5048 - val_loss: 2.3417\n",
      "Epoch 1260/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 11.9803 - val_loss: 2.3357\n",
      "Epoch 1261/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 3.7612 - val_loss: 2.3300\n",
      "Epoch 1262/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.9043 - val_loss: 2.3244\n",
      "Epoch 1263/2000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 9.2227 - val_loss: 2.3196\n",
      "Epoch 1264/2000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 7.5740 - val_loss: 2.3146\n",
      "Epoch 1265/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 6.0828 - val_loss: 2.3101\n",
      "Epoch 1266/2000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 14.4631 - val_loss: 2.3053\n",
      "Epoch 1267/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 6.5302 - val_loss: 2.3003\n",
      "Epoch 1268/2000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 5.9474 - val_loss: 2.2954\n",
      "Epoch 1269/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 2.1042 - val_loss: 2.2909\n",
      "Epoch 1270/2000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.0358 - val_loss: 2.2867\n",
      "Epoch 1271/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.3008 - val_loss: 2.2822\n",
      "Epoch 1272/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 7.2820 - val_loss: 2.2777\n",
      "Epoch 1273/2000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 3.8366 - val_loss: 2.2734\n",
      "Epoch 1274/2000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 6.7045 - val_loss: 2.2691\n",
      "Epoch 1275/2000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 7.3225 - val_loss: 2.2647\n",
      "Epoch 1276/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.0119 - val_loss: 2.2603\n",
      "Epoch 1277/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 11.9045 - val_loss: 2.2557\n",
      "Epoch 1278/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.8035 - val_loss: 2.2512\n",
      "Epoch 1279/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 5.1004 - val_loss: 2.2467\n",
      "Epoch 1280/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.8966 - val_loss: 2.2421\n",
      "Epoch 1281/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 3.3679 - val_loss: 2.2379\n",
      "Epoch 1282/2000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.2962 - val_loss: 2.2343\n",
      "Epoch 1283/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 10.2854 - val_loss: 2.2304\n",
      "Epoch 1284/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 6.5095 - val_loss: 2.2260\n",
      "Epoch 1285/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 7.9654 - val_loss: 2.2220\n",
      "Epoch 1286/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.9837 - val_loss: 2.2188\n",
      "Epoch 1287/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 6.7106 - val_loss: 2.2158\n",
      "Epoch 1288/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.6517 - val_loss: 2.2127\n",
      "Epoch 1289/2000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.7747 - val_loss: 2.2095\n",
      "Epoch 1290/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.2533 - val_loss: 2.2061\n",
      "Epoch 1291/2000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 6.3352 - val_loss: 2.2023\n",
      "Epoch 1292/2000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 7.5696 - val_loss: 2.1991\n",
      "Epoch 1293/2000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 5.2890 - val_loss: 2.1956\n",
      "Epoch 1294/2000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 6.9477 - val_loss: 2.1922\n",
      "Epoch 1295/2000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 7.9124 - val_loss: 2.1890\n",
      "Epoch 1296/2000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 4.4804 - val_loss: 2.1864\n",
      "Epoch 1297/2000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 4.5653 - val_loss: 2.1841\n",
      "Epoch 1298/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 8.7015 - val_loss: 2.1822\n",
      "Epoch 1299/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.4954 - val_loss: 2.1801\n",
      "Epoch 1300/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 5.8562 - val_loss: 2.1782\n",
      "Epoch 1301/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.1853 - val_loss: 2.1759\n",
      "Epoch 1302/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 6.3985 - val_loss: 2.1738\n",
      "Epoch 1303/2000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 4.3955 - val_loss: 2.1721\n",
      "Epoch 1304/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.6515 - val_loss: 2.1708\n",
      "Epoch 1305/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 2.4422 - val_loss: 2.1697\n",
      "Epoch 1306/2000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1.4965 - val_loss: 2.1687\n",
      "Epoch 1307/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.3815 - val_loss: 2.1675\n",
      "Epoch 1308/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 7.8776 - val_loss: 2.1670\n",
      "Epoch 1309/2000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 10.0285 - val_loss: 2.1662\n",
      "Epoch 1310/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 8.1026 - val_loss: 2.1652\n",
      "Epoch 1311/2000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.4443 - val_loss: 2.1641\n",
      "Epoch 1312/2000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 6.5151 - val_loss: 2.1625\n",
      "Epoch 1313/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 6.9674 - val_loss: 2.1607\n",
      "Epoch 1314/2000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 6.6502 - val_loss: 2.1588\n",
      "Epoch 1315/2000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 6.6905 - val_loss: 2.1572\n",
      "Epoch 1316/2000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 7.0095 - val_loss: 2.1555\n",
      "Epoch 1317/2000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 5.4826 - val_loss: 2.1535\n",
      "Epoch 1318/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 7.5943 - val_loss: 2.1516\n",
      "Epoch 1319/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.9431 - val_loss: 2.1491\n",
      "Epoch 1320/2000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 8.6749 - val_loss: 2.1470\n",
      "Epoch 1321/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 10.6135 - val_loss: 2.1448\n",
      "Epoch 1322/2000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 9.5057 - val_loss: 2.1425\n",
      "Epoch 1323/2000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 8.8797 - val_loss: 2.1402\n",
      "Epoch 1324/2000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 2.1810 - val_loss: 2.1382\n",
      "Epoch 1325/2000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 4.2567 - val_loss: 2.1366\n",
      "Epoch 1326/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 6.9212 - val_loss: 2.1351\n",
      "Epoch 1327/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.3293 - val_loss: 2.1337\n",
      "Epoch 1328/2000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 5.4689 - val_loss: 2.1320\n",
      "Epoch 1329/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 8.9761 - val_loss: 2.1300\n",
      "Epoch 1330/2000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 3.3296 - val_loss: 2.1278\n",
      "Epoch 1331/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 9.8972 - val_loss: 2.1253\n",
      "Epoch 1332/2000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 5.1172 - val_loss: 2.1228\n",
      "Epoch 1333/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 9.2961 - val_loss: 2.1206\n",
      "Epoch 1334/2000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 6.6761 - val_loss: 2.1182\n",
      "Epoch 1335/2000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 8.1169 - val_loss: 2.1160\n",
      "Epoch 1336/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 9.3844 - val_loss: 2.1135\n",
      "Epoch 1337/2000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 8.0962 - val_loss: 2.1108\n",
      "Epoch 1338/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 3.9379 - val_loss: 2.1080\n",
      "Epoch 1339/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 2.4763 - val_loss: 2.1060\n",
      "Epoch 1340/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.6708 - val_loss: 2.1038\n",
      "Epoch 1341/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 7.8074 - val_loss: 2.1017\n",
      "Epoch 1342/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 9.9421 - val_loss: 2.0992\n",
      "Epoch 1343/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 6.0919 - val_loss: 2.0964\n",
      "Epoch 1344/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 7.1885 - val_loss: 2.0939\n",
      "Epoch 1345/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.1753 - val_loss: 2.0912\n",
      "Epoch 1346/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 13.4408 - val_loss: 2.0882\n",
      "Epoch 1347/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.1412 - val_loss: 2.0858\n",
      "Epoch 1348/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 6.4220 - val_loss: 2.0834\n",
      "Epoch 1349/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 6.0557 - val_loss: 2.0814\n",
      "Epoch 1350/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 6.1976 - val_loss: 2.0789\n",
      "Epoch 1351/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 7.4455 - val_loss: 2.0771\n",
      "Epoch 1352/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 8.9745 - val_loss: 2.0748\n",
      "Epoch 1353/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.5512 - val_loss: 2.0724\n",
      "Epoch 1354/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 10.3384 - val_loss: 2.0698\n",
      "Epoch 1355/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.5177 - val_loss: 2.0673\n",
      "Epoch 1356/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.3761 - val_loss: 2.0655\n",
      "Epoch 1357/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.5198 - val_loss: 2.0636\n",
      "Epoch 1358/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 9.9209 - val_loss: 2.0616\n",
      "Epoch 1359/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.9988 - val_loss: 2.0597\n",
      "Epoch 1360/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.5916 - val_loss: 2.0576\n",
      "Epoch 1361/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.8095 - val_loss: 2.0557\n",
      "Epoch 1362/2000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 7.1737 - val_loss: 2.0534\n",
      "Epoch 1363/2000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 3.7442 - val_loss: 2.0517\n",
      "Epoch 1364/2000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.9452 - val_loss: 2.0502\n",
      "Epoch 1365/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 6.2647 - val_loss: 2.0482\n",
      "Epoch 1366/2000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 6.1265 - val_loss: 2.0460\n",
      "Epoch 1367/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.7270 - val_loss: 2.0434\n",
      "Epoch 1368/2000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 8.7902 - val_loss: 2.0408\n",
      "Epoch 1369/2000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.4860 - val_loss: 2.0386\n",
      "Epoch 1370/2000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 5.9266 - val_loss: 2.0362\n",
      "Epoch 1371/2000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 2.5674 - val_loss: 2.0343\n",
      "Epoch 1372/2000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 10.5994 - val_loss: 2.0322\n",
      "Epoch 1373/2000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 8.8216 - val_loss: 2.0301\n",
      "Epoch 1374/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.2325 - val_loss: 2.0282\n",
      "Epoch 1375/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.4634 - val_loss: 2.0268\n",
      "Epoch 1376/2000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 4.2444 - val_loss: 2.0256\n",
      "Epoch 1377/2000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 6.1277 - val_loss: 2.0242\n",
      "Epoch 1378/2000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 10.3068 - val_loss: 2.0226\n",
      "Epoch 1379/2000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 2.0441 - val_loss: 2.0212\n",
      "Epoch 1380/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 6.1261 - val_loss: 2.0196\n",
      "Epoch 1381/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 11.8260 - val_loss: 2.0175\n",
      "Epoch 1382/2000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 5.2308 - val_loss: 2.0159\n",
      "Epoch 1383/2000\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 6.7906 - val_loss: 2.0144\n",
      "Epoch 1384/2000\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 4.9394 - val_loss: 2.0130\n",
      "Epoch 1385/2000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 6.4320 - val_loss: 2.0114\n",
      "Epoch 1386/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 9.3290 - val_loss: 2.0096\n",
      "Epoch 1387/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.7813 - val_loss: 2.0075\n",
      "Epoch 1388/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 8.9847 - val_loss: 2.0050\n",
      "Epoch 1389/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.6754 - val_loss: 2.0029\n",
      "Epoch 1390/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.0405 - val_loss: 2.0009\n",
      "Epoch 1391/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 7.0654 - val_loss: 1.9990\n",
      "Epoch 1392/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.9560 - val_loss: 1.9969\n",
      "Epoch 1393/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.1398 - val_loss: 1.9955\n",
      "Epoch 1394/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.2328 - val_loss: 1.9942\n",
      "Epoch 1395/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 2.8958 - val_loss: 1.9932\n",
      "Epoch 1396/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 10.3808 - val_loss: 1.9922\n",
      "Epoch 1397/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.5139 - val_loss: 1.9912\n",
      "Epoch 1398/2000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 10.3337 - val_loss: 1.9901\n",
      "Epoch 1399/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 9.9946 - val_loss: 1.9883\n",
      "Epoch 1400/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.0579 - val_loss: 1.9868\n",
      "Epoch 1401/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.7600 - val_loss: 1.9857\n",
      "Epoch 1402/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 6.2303 - val_loss: 1.9843\n",
      "Epoch 1403/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 8.7352 - val_loss: 1.9822\n",
      "Epoch 1404/2000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 7.5616 - val_loss: 1.9804\n",
      "Epoch 1405/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 6.4162 - val_loss: 1.9787\n",
      "Epoch 1406/2000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 5.7904 - val_loss: 1.9771\n",
      "Epoch 1407/2000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.2211 - val_loss: 1.9755\n",
      "Epoch 1408/2000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 5.8837 - val_loss: 1.9746\n",
      "Epoch 1409/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.7090 - val_loss: 1.9739\n",
      "Epoch 1410/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 6.7541 - val_loss: 1.9735\n",
      "Epoch 1411/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 8.6178 - val_loss: 1.9729\n",
      "Epoch 1412/2000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 8.0740 - val_loss: 1.9721\n",
      "Epoch 1413/2000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 6.1741 - val_loss: 1.9711\n",
      "Epoch 1414/2000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 7.7207 - val_loss: 1.9701\n",
      "Epoch 1415/2000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 5.0709 - val_loss: 1.9690\n",
      "Epoch 1416/2000\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 8.3420 - val_loss: 1.9670\n",
      "Epoch 1417/2000\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 5.6623 - val_loss: 1.9654\n",
      "Epoch 1418/2000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 10.7401 - val_loss: 1.9637\n",
      "Epoch 1419/2000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 4.4308 - val_loss: 1.9617\n",
      "Epoch 1420/2000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 5.0510 - val_loss: 1.9597\n",
      "Epoch 1421/2000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 3.6491 - val_loss: 1.9576\n",
      "Epoch 1422/2000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 6.4119 - val_loss: 1.9555\n",
      "Epoch 1423/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 2.1042 - val_loss: 1.9534\n",
      "Epoch 1424/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 7.3371 - val_loss: 1.9513\n",
      "Epoch 1425/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 5.3068 - val_loss: 1.9493\n",
      "Epoch 1426/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.2030 - val_loss: 1.9473\n",
      "Epoch 1427/2000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 6.4052 - val_loss: 1.9452\n",
      "Epoch 1428/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.5199 - val_loss: 1.9434\n",
      "Epoch 1429/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.1816 - val_loss: 1.9417\n",
      "Epoch 1430/2000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 10.2608 - val_loss: 1.9400\n",
      "Epoch 1431/2000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 3.9066 - val_loss: 1.9382\n",
      "Epoch 1432/2000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.8100 - val_loss: 1.9369\n",
      "Epoch 1433/2000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 7.2576 - val_loss: 1.9356\n",
      "Epoch 1434/2000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 6.6928 - val_loss: 1.9342\n",
      "Epoch 1435/2000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 7.9342 - val_loss: 1.9328\n",
      "Epoch 1436/2000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 7.7987 - val_loss: 1.9314\n",
      "Epoch 1437/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 7.3001 - val_loss: 1.9301\n",
      "Epoch 1438/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.9349 - val_loss: 1.9291\n",
      "Epoch 1439/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.9054 - val_loss: 1.9282\n",
      "Epoch 1440/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 7.8272 - val_loss: 1.9272\n",
      "Epoch 1441/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 9.9994 - val_loss: 1.9264\n",
      "Epoch 1442/2000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 2.6507 - val_loss: 1.9258\n",
      "Epoch 1443/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 6.2921 - val_loss: 1.9252\n",
      "Epoch 1444/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.2028 - val_loss: 1.9247\n",
      "Epoch 1445/2000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 4.8090 - val_loss: 1.9242\n",
      "Epoch 1446/2000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 8.9262 - val_loss: 1.9237\n",
      "Epoch 1447/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 7.4597 - val_loss: 1.9230\n",
      "Epoch 1448/2000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 7.3690 - val_loss: 1.9225\n",
      "Epoch 1449/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 7.6973 - val_loss: 1.9220\n",
      "Epoch 1450/2000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1726 - val_loss: 1.9216\n",
      "Epoch 1451/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.4093 - val_loss: 1.9210\n",
      "Epoch 1452/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 7.9122 - val_loss: 1.9204\n",
      "Epoch 1453/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 8.0587 - val_loss: 1.9195\n",
      "Epoch 1454/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 9.8278 - val_loss: 1.9189\n",
      "Epoch 1455/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 6.4068 - val_loss: 1.9182\n",
      "Epoch 1456/2000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 6.3047 - val_loss: 1.9172\n",
      "Epoch 1457/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.8472 - val_loss: 1.9163\n",
      "Epoch 1458/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.3030 - val_loss: 1.9154\n",
      "Epoch 1459/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 6.9469 - val_loss: 1.9143\n",
      "Epoch 1460/2000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 11.3962 - val_loss: 1.9131\n",
      "Epoch 1461/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.4704 - val_loss: 1.9120\n",
      "Epoch 1462/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 7.0927 - val_loss: 1.9110\n",
      "Epoch 1463/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.8080 - val_loss: 1.9102\n",
      "Epoch 1464/2000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 10.7263 - val_loss: 1.9093\n",
      "Epoch 1465/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 6.7990 - val_loss: 1.9087\n",
      "Epoch 1466/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.6610 - val_loss: 1.9085\n",
      "Epoch 1467/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.2509 - val_loss: 1.9080\n",
      "Epoch 1468/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.5590 - val_loss: 1.9077\n",
      "Epoch 1469/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 8.5043 - val_loss: 1.9073\n",
      "Epoch 1470/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.9572 - val_loss: 1.9068\n",
      "Epoch 1471/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 6.4269 - val_loss: 1.9060\n",
      "Epoch 1472/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 9.0176 - val_loss: 1.9058\n",
      "Epoch 1473/2000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 5.2896 - val_loss: 1.9054\n",
      "Epoch 1474/2000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 5.0461 - val_loss: 1.9053\n",
      "Epoch 1475/2000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 7.0463 - val_loss: 1.9049\n",
      "Epoch 1476/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 6.1527 - val_loss: 1.9045\n",
      "Epoch 1477/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 2.6242 - val_loss: 1.9043\n",
      "Epoch 1478/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 7.9900 - val_loss: 1.9039\n",
      "Epoch 1479/2000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 6.1314 - val_loss: 1.9036\n",
      "Epoch 1480/2000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 17.0817 - val_loss: 1.9033\n",
      "Epoch 1481/2000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 5.5657 - val_loss: 1.9028\n",
      "Epoch 1482/2000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 6.4264 - val_loss: 1.9024\n",
      "Epoch 1483/2000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 6.0455 - val_loss: 1.9022\n",
      "Epoch 1484/2000\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 7.8158 - val_loss: 1.9020\n",
      "Epoch 1485/2000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 7.3696 - val_loss: 1.9018\n",
      "Epoch 1486/2000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 9.1832 - val_loss: 1.9017\n",
      "Epoch 1487/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.5019 - val_loss: 1.9017\n",
      "Epoch 1488/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 5.7700 - val_loss: 1.9016\n",
      "Epoch 1489/2000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 7.1553 - val_loss: 1.9016\n",
      "Epoch 1490/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.1596 - val_loss: 1.9016\n",
      "Epoch 1491/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.7421 - val_loss: 1.9018\n",
      "Epoch 1492/2000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 6.6084 - val_loss: 1.9019\n",
      "Epoch 1493/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.6639 - val_loss: 1.9018\n",
      "Epoch 1494/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.7484 - val_loss: 1.9017\n",
      "Epoch 1495/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 8.9172 - val_loss: 1.9017\n",
      "Epoch 1496/2000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 3.3052 - val_loss: 1.9014\n",
      "Epoch 1497/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.0495 - val_loss: 1.9010\n",
      "Epoch 1498/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 5.3259 - val_loss: 1.9005\n",
      "Epoch 1499/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 6.4471 - val_loss: 1.8995\n",
      "Epoch 1500/2000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 5.4680 - val_loss: 1.8986\n",
      "Epoch 1501/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 7.2791 - val_loss: 1.8981\n",
      "Epoch 1502/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 6.8496 - val_loss: 1.8979\n",
      "Epoch 1503/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.1545 - val_loss: 1.8972\n",
      "Epoch 1504/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 3.3154 - val_loss: 1.8969\n",
      "Epoch 1505/2000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.5493 - val_loss: 1.8965\n",
      "Epoch 1506/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.3699 - val_loss: 1.8959\n",
      "Epoch 1507/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 8.1950 - val_loss: 1.8955\n",
      "Epoch 1508/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 6.4410 - val_loss: 1.8949\n",
      "Epoch 1509/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.1352 - val_loss: 1.8942\n",
      "Epoch 1510/2000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 5.0267 - val_loss: 1.8936\n",
      "Epoch 1511/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.3264 - val_loss: 1.8934\n",
      "Epoch 1512/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 6.3298 - val_loss: 1.8935\n",
      "Epoch 1513/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 2.9641 - val_loss: 1.8935\n",
      "Epoch 1514/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 14.1802 - val_loss: 1.8934\n",
      "Epoch 1515/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 7.0317 - val_loss: 1.8935\n",
      "Epoch 1516/2000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.1097 - val_loss: 1.8932\n",
      "Epoch 1517/2000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 6.5546 - val_loss: 1.8931\n",
      "Epoch 1518/2000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 5.0353 - val_loss: 1.8928\n",
      "Epoch 1519/2000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 6.8217 - val_loss: 1.8922\n",
      "Epoch 1520/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 8.8303 - val_loss: 1.8915\n",
      "Epoch 1521/2000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 7.6903 - val_loss: 1.8904\n",
      "Epoch 1522/2000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 3.9218 - val_loss: 1.8892\n",
      "Epoch 1523/2000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 2.9724 - val_loss: 1.8880\n",
      "Epoch 1524/2000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 6.4175 - val_loss: 1.8865\n",
      "Epoch 1525/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.1760 - val_loss: 1.8855\n",
      "Epoch 1526/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 8.1144 - val_loss: 1.8849\n",
      "Epoch 1527/2000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 7.0367 - val_loss: 1.8841\n",
      "Epoch 1528/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 6.9668 - val_loss: 1.8832\n",
      "Epoch 1529/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.6758 - val_loss: 1.8825\n",
      "Epoch 1530/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.8339 - val_loss: 1.8817\n",
      "Epoch 1531/2000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 7.7669 - val_loss: 1.8810\n",
      "Epoch 1532/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 8.5462 - val_loss: 1.8801\n",
      "Epoch 1533/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 3.2358 - val_loss: 1.8796\n",
      "Epoch 1534/2000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 5.2002 - val_loss: 1.8788\n",
      "Epoch 1535/2000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 3.6693 - val_loss: 1.8782\n",
      "Epoch 1536/2000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 6.4957 - val_loss: 1.8777\n",
      "Epoch 1537/2000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 5.3350 - val_loss: 1.8774\n",
      "Epoch 1538/2000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 5.2634 - val_loss: 1.8770\n",
      "Epoch 1539/2000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 10.0963 - val_loss: 1.8766\n",
      "Epoch 1540/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 8.4254 - val_loss: 1.8761\n",
      "Epoch 1541/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 7.0246 - val_loss: 1.8757\n",
      "Epoch 1542/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 6.1863 - val_loss: 1.8752\n",
      "Epoch 1543/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 6.7830 - val_loss: 1.8751\n",
      "Epoch 1544/2000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 7.4338 - val_loss: 1.8750\n",
      "Epoch 1545/2000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.0082 - val_loss: 1.8746\n",
      "Epoch 1546/2000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 3.4455 - val_loss: 1.8742\n",
      "Epoch 1547/2000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 6.5795 - val_loss: 1.8738\n",
      "Epoch 1548/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 7.3975 - val_loss: 1.8733\n",
      "Epoch 1549/2000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.2376 - val_loss: 1.8726\n",
      "Epoch 1550/2000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1.1958 - val_loss: 1.8721\n",
      "Epoch 1551/2000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 10.6878 - val_loss: 1.8717\n",
      "Epoch 1552/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 8.0913 - val_loss: 1.8712\n",
      "Epoch 1553/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.3764 - val_loss: 1.8708\n",
      "Epoch 1554/2000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 3.6075 - val_loss: 1.8700\n",
      "Epoch 1555/2000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 3.4939 - val_loss: 1.8693\n",
      "Epoch 1556/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 6.2750 - val_loss: 1.8686\n",
      "Epoch 1557/2000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 2.6916 - val_loss: 1.8680\n",
      "Epoch 1558/2000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 10.4036 - val_loss: 1.8673\n",
      "Epoch 1559/2000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 3.8860 - val_loss: 1.8670\n",
      "Epoch 1560/2000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 9.3633 - val_loss: 1.8664\n",
      "Epoch 1561/2000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 3.4094 - val_loss: 1.8660\n",
      "Epoch 1562/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 2.9461 - val_loss: 1.8656\n",
      "Epoch 1563/2000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 6.5371 - val_loss: 1.8650\n",
      "Epoch 1564/2000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 8.7143 - val_loss: 1.8643\n",
      "Epoch 1565/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 7.3820 - val_loss: 1.8638\n",
      "Epoch 1566/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 7.5896 - val_loss: 1.8635\n",
      "Epoch 1567/2000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 9.4726 - val_loss: 1.8634\n",
      "Epoch 1568/2000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 4.5908 - val_loss: 1.8633\n",
      "Epoch 1569/2000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 10.6277 - val_loss: 1.8630\n",
      "Epoch 1570/2000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 5.1829 - val_loss: 1.8629\n",
      "Epoch 1571/2000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 6.8689 - val_loss: 1.8629\n",
      "Epoch 1572/2000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 6.2628 - val_loss: 1.8631\n",
      "Epoch 1573/2000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 7.7910 - val_loss: 1.8634\n",
      "Epoch 1574/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 5.7221 - val_loss: 1.8637\n",
      "Epoch 1575/2000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 7.5358 - val_loss: 1.8639\n",
      "Epoch 1576/2000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.5347 - val_loss: 1.8641\n",
      "Epoch 1577/2000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.6585 - val_loss: 1.8644\n",
      "Epoch 1578/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 10.8280 - val_loss: 1.8647\n",
      "Epoch 1579/2000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 7.2541 - val_loss: 1.8648\n",
      "Epoch 1580/2000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 7.3649 - val_loss: 1.8646\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(input_train_regular_cycle, output_train_regular_cycle, epochs=2000, batch_size=32, validation_split=0.2, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the loss and val loss\n",
    "plt.figure(figsize=(4, 3))\n",
    "plt.plot(history.history['loss'], '-', linewidth=2)\n",
    "plt.plot(history.history['val_loss'], '--', linewidth=2)\n",
    "plt.grid(True)\n",
    "plt.legend(['Train', 'Validation'])\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.title('Case 2: LSTM model loss')\n",
    "# log scale\n",
    "#plt.yscale('log')\n",
    "\n",
    "# add a zoom in epoch 70 to 100\n",
    "ax = plt.axes([0.6, 0.4, .20, .20])\n",
    "plt.plot(history.history['loss'], '-', linewidth=2)\n",
    "plt.plot(history.history['val_loss'], '--', linewidth=2)\n",
    "plt.grid(True)\n",
    "ax.set_ylim(1, 6)\n",
    "ax.set_xlim(1500, 1650)\n",
    "\n",
    "\n",
    "# save history\n",
    "history_df = pd.DataFrame(history.history)\n",
    "history_df.to_csv('case2_history_lstm.csv', index=False)\n",
    "\n",
    "# save figure\n",
    "fig = plt.gcf()\n",
    "fig.savefig('case2_loss_lstm.eps', dpi=300, bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-25 18:59:44.085104: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-05-25 18:59:44.086775: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-05-25 18:59:44.088109: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-05-25 18:59:44.258333: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-05-25 18:59:44.259808: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-05-25 18:59:44.261052: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-05-25 18:59:44.432810: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-05-25 18:59:44.434513: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-05-25 18:59:44.435761: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fc4fe79d000> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 791ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n"
     ]
    }
   ],
   "source": [
    "# make predictions\n",
    "trainPredict = model.predict(input_train_regular_cycle)\n",
    "testPredict = model.predict(input_test_regular_cycle)\n",
    "testPredict = np.round(testPredict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score: 2.55 RMSE\n",
      "Test Score: 2.10 MAE\n",
      "Test Score: -2.18 R2\n"
     ]
    }
   ],
   "source": [
    "# calculate root mean squared error\n",
    "testScore = np.sqrt(mean_squared_error(output_test_regular_cycle, testPredict))\n",
    "print('Test Score: %.2f RMSE' % (testScore))\n",
    "\n",
    "# calculate mean absolute error\n",
    "testScore = mean_absolute_error(output_test_regular_cycle, testPredict)\n",
    "print('Test Score: %.2f MAE' % (testScore))\n",
    "\n",
    "# calculate r2 score\n",
    "testScore = r2_score(output_test_regular_cycle, testPredict)\n",
    "print('Test Score: %.2f R2' % (testScore))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot baseline and predictions\n",
    "plt.figure(figsize=(4, 3))\n",
    "plt.plot(np.arange(5),output_test_regular_cycle[:,0], '-->', linewidth=2.0)\n",
    "plt.plot(np.arange(5, 6),testPredict[0,0], '-o')\n",
    "# round the number in axis\n",
    "plt.gca().yaxis.set_major_locator(plt.MaxNLocator(integer=True))\n",
    "plt.ylabel('Days')\n",
    "plt.xlabel('Cycle number')\n",
    "plt.legend(['Cycle duration', 'Prediction (LSTM)'])\n",
    "plt.title('Case 2: Predict the next cycle duration')\n",
    "plt.grid(True)\n",
    "\n",
    "# save figure\n",
    "fig = plt.gcf()\n",
    "fig.savefig('case2_prediction_lstm.eps', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(4, 3))\n",
    "plt.plot(np.arange(5),output_test_regular_cycle[:,1], '-->', linewidth=2.0)\n",
    "plt.plot(np.arange(5, 6),testPredict[0,1], '-o')\n",
    "# round the number in axis\n",
    "plt.gca().yaxis.set_major_locator(plt.MaxNLocator(integer=True))\n",
    "#set the y axis range\n",
    "plt.ylim(4, 7)\n",
    "plt.ylabel('Days')\n",
    "plt.xlabel('Periods number')\n",
    "plt.legend(['Period duration', 'Prediction (LSTM)'])\n",
    "plt.title('Case 2: Predict the next period duration')\n",
    "# save figure\n",
    "\n",
    "fig = plt.gcf()\n",
    "fig.savefig('case2_prediction_period_lstm.eps', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model \n",
    "model.save('case2_lstm_model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cilab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "db30be8d3737aa80edf161684c13650df139a6b16e3a6f806a23c612cab06771"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
